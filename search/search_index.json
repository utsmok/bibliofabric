{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Bibliofabric","text":"<p>Welcome to the documentation for Bibliofabric!</p> <p><code>bibliofabric</code> is a Python library providing a generic, extensible framework for building modern, asynchronous API clients. It includes built-in support for features like authentication, rate limiting, retries, and caching.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Asynchronous by Design: Built on <code>httpx</code> for high-performance, non-blocking I/O.</li> <li>Extensible: Use protocols and mixins to easily create new clients for any API.</li> <li>Robust: Includes built-in error handling, request retries with exponential backoff, and rate limit management.</li> <li>Type-Safe: Fully type-hinted for a better development experience and fewer runtime errors.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To get started, explore the API Reference section to understand the core components of the framework.</p>"},{"location":"auth/","title":"Authentication","text":""},{"location":"auth/#bibliofabric.auth","title":"<code>bibliofabric.auth</code>","text":""},{"location":"auth/#bibliofabric.auth.AuthStrategy","title":"<code>AuthStrategy</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol defining the interface for various authentication strategies.</p> <p>Concrete implementations of this protocol handle the specifics of adding authentication information (e.g., headers, tokens) to an HTTP request.</p> Source code in <code>src/bibliofabric/auth.py</code> <pre><code>class AuthStrategy(Protocol):\n    \"\"\"Protocol defining the interface for various authentication strategies.\n\n    Concrete implementations of this protocol handle the specifics of adding\n    authentication information (e.g., headers, tokens) to an HTTP request.\n    \"\"\"\n\n    async def async_authenticate(self, request: httpx.Request) -&gt; None:\n        \"\"\"\n        Asynchronously modifies the request to add authentication information.\n\n        Args:\n            request: The httpx.Request object to modify.\n\n        Raises:\n            AuthError: If authentication fails (e.g., token fetching).\n            ConfigurationError: If required configuration for the strategy is missing.\n        \"\"\"\n        ...\n\n    async def async_close(self) -&gt; None:\n        \"\"\"\n        Asynchronously closes any underlying resources used by the auth strategy,\n        if applicable (e.g., an HTTP client for token fetching).\n        This method should be idempotent.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"auth/#bibliofabric.auth.AuthStrategy.async_authenticate","title":"<code>async_authenticate(request)</code>  <code>async</code>","text":"<p>Asynchronously modifies the request to add authentication information.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The httpx.Request object to modify.</p> required <p>Raises:</p> Type Description <code>AuthError</code> <p>If authentication fails (e.g., token fetching).</p> <code>ConfigurationError</code> <p>If required configuration for the strategy is missing.</p> Source code in <code>src/bibliofabric/auth.py</code> <pre><code>async def async_authenticate(self, request: httpx.Request) -&gt; None:\n    \"\"\"\n    Asynchronously modifies the request to add authentication information.\n\n    Args:\n        request: The httpx.Request object to modify.\n\n    Raises:\n        AuthError: If authentication fails (e.g., token fetching).\n        ConfigurationError: If required configuration for the strategy is missing.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"auth/#bibliofabric.auth.AuthStrategy.async_close","title":"<code>async_close()</code>  <code>async</code>","text":"<p>Asynchronously closes any underlying resources used by the auth strategy, if applicable (e.g., an HTTP client for token fetching). This method should be idempotent.</p> Source code in <code>src/bibliofabric/auth.py</code> <pre><code>async def async_close(self) -&gt; None:\n    \"\"\"\n    Asynchronously closes any underlying resources used by the auth strategy,\n    if applicable (e.g., an HTTP client for token fetching).\n    This method should be idempotent.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"auth/#bibliofabric.auth.AuthStrategyType","title":"<code>AuthStrategyType</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enumeration of available authentication strategy types.</p> <p>Used in configuration to specify which authentication method to use.</p> Source code in <code>src/bibliofabric/auth.py</code> <pre><code>class AuthStrategyType(Enum):\n    \"\"\"Enumeration of available authentication strategy types.\n\n    Used in configuration to specify which authentication method to use.\n    \"\"\"\n\n    NONE = \"none\"\n    STATIC_TOKEN = \"static_token\"\n    CLIENT_CREDENTIALS = \"client_credentials\"\n</code></pre>"},{"location":"auth/#bibliofabric.auth.ClientCredentialsAuth","title":"<code>ClientCredentialsAuth</code>","text":"<p>Implements AuthStrategy using OAuth2 Client Credentials Grant Flow.</p> <p>This strategy fetches a Bearer token from a specified token URL using client ID and client secret, then uses this token for subsequent API requests. It handles token fetching and includes a lock to prevent concurrent token requests.</p> <p>Attributes:</p> Name Type Description <code>_client_id</code> <code>str</code> <p>The OAuth2 client ID.</p> <code>_client_secret</code> <code>str</code> <p>The OAuth2 client secret.</p> <code>_token_url</code> <code>str</code> <p>The URL of the OAuth2 token endpoint.</p> <code>_access_token</code> <code>str | None</code> <p>The currently active access token.</p> <code>_token_client</code> <code>AsyncClient | None</code> <p>An internal httpx.AsyncClient for fetching the token.</p> <code>_fetch_lock</code> <p>An asyncio.Lock to prevent race conditions during token fetching.</p> Source code in <code>src/bibliofabric/auth.py</code> <pre><code>class ClientCredentialsAuth:\n    \"\"\"Implements AuthStrategy using OAuth2 Client Credentials Grant Flow.\n\n    This strategy fetches a Bearer token from a specified token URL using\n    client ID and client secret, then uses this token for subsequent API requests.\n    It handles token fetching and includes a lock to prevent concurrent token requests.\n\n    Attributes:\n        _client_id: The OAuth2 client ID.\n        _client_secret: The OAuth2 client secret.\n        _token_url: The URL of the OAuth2 token endpoint.\n        _access_token: The currently active access token.\n        _token_client: An internal httpx.AsyncClient for fetching the token.\n        _fetch_lock: An asyncio.Lock to prevent race conditions during token fetching.\n    \"\"\"\n\n    def __init__(\n        self, client_id: str | None, client_secret: str | None, token_url: str | None\n    ):\n        if not all([client_id, client_secret, token_url]):\n            raise ConfigurationError(\n                \"ClientCredentialsAuth requires 'client_id', 'client_secret', and 'token_url'.\"\n            )\n        assert client_id is not None, \"client_id cannot be None here\"\n        assert client_secret is not None, \"client_secret cannot be None here\"\n        assert token_url is not None, \"token_url cannot be None here\"\n        self._client_id: str = client_id\n        self._client_secret: str = client_secret\n        self._token_url: str = token_url\n        self._access_token: str | None = None\n        self._token_client: httpx.AsyncClient | None = None\n        self._fetch_lock = asyncio.Lock()\n        logger.debug(\"ClientCredentialsAuth initialized.\")\n\n    async def _get_token_client(self) -&gt; httpx.AsyncClient:\n        \"\"\"Lazily initializes and returns an internal httpx.AsyncClient for token requests.\n\n        Returns:\n            An httpx.AsyncClient instance.\n        \"\"\"\n        if self._token_client is None:\n            self._token_client = httpx.AsyncClient(\n                timeout=15.0\n            )  # Standard timeout for token requests\n        return self._token_client\n\n    async def _fetch_access_token(self) -&gt; str:\n        \"\"\"Fetches a new OAuth2 access token using the client credentials grant type.\n\n        This method handles the POST request to the token URL and extracts the\n        access token from the JSON response. It uses a lock to prevent multiple\n        concurrent requests for a new token.\n\n        Returns:\n            The fetched access token as a string.\n\n        Raises:\n            AuthError: If token fetching fails due to HTTP errors, network issues,\n                       or an invalid response from the token endpoint.\n        \"\"\"\n        async with self._fetch_lock:\n            # Double-check if token was fetched while waiting for the lock\n            if self._access_token:\n                return self._access_token\n\n            logger.info(f\"Fetching new access token from {self._token_url}\")\n            client = await self._get_token_client()\n            try:\n                response = await client.post(\n                    url=self._token_url,\n                    auth=httpx.BasicAuth(\n                        username=self._client_id, password=self._client_secret\n                    ),\n                    data={\"grant_type\": \"client_credentials\"},\n                )\n                response.raise_for_status()  # Raise HTTPStatusError for bad responses (4xx or 5xx)\n                token_data = response.json()\n                access_token = token_data.get(\"access_token\")\n                if not access_token:\n                    raise AuthError(\"Access token not found in token response.\")\n                # TODO: Handle token expiry ('expires_in') for future automatic refresh\n                # expires_in = token_data.get(\"expires_in\")\n                logger.info(\"Successfully fetched new access token.\")\n                self._access_token = access_token\n                assert self._access_token is not None, \"Access token should be set here\"\n                return self._access_token\n            except httpx.HTTPStatusError as e:\n                logger.error(\n                    f\"HTTP error fetching token: {e.response.status_code} - {e.response.text}\"\n                )\n                raise AuthError(\n                    f\"Failed to fetch access token: {e.response.status_code} - {e.response.text}\"\n                ) from e\n            except (httpx.RequestError, Exception) as e:\n                logger.error(f\"Error fetching token: {e}\")\n                raise AuthError(f\"Failed to fetch access token: {e}\") from e\n\n    async def async_authenticate(self, request: httpx.Request) -&gt; None:\n        \"\"\"Ensures a valid token is fetched and adds the Authorization header.\"\"\"\n        logger.trace(\"Authenticating request using ClientCredentialsAuth.\")\n        if not self._access_token:\n            # Fetch token if not already available (first time or after expiry if implemented)\n            await self._fetch_access_token()\n\n        if not self._access_token:\n            # Should not happen if fetch was successful, but check anyway\n            raise AuthError(\"Authentication failed: Could not obtain access token.\")\n\n        request.headers[\"Authorization\"] = f\"Bearer {self._access_token}\"\n\n    async def async_close(self) -&gt; None:\n        \"\"\"Closes the internal HTTP client used for token fetching.\"\"\"\n        if self._token_client:\n            await self._token_client.aclose()\n            self._token_client = None\n            logger.debug(\"ClientCredentialsAuth internal client closed.\")\n</code></pre>"},{"location":"auth/#bibliofabric.auth.ClientCredentialsAuth.async_authenticate","title":"<code>async_authenticate(request)</code>  <code>async</code>","text":"<p>Ensures a valid token is fetched and adds the Authorization header.</p> Source code in <code>src/bibliofabric/auth.py</code> <pre><code>async def async_authenticate(self, request: httpx.Request) -&gt; None:\n    \"\"\"Ensures a valid token is fetched and adds the Authorization header.\"\"\"\n    logger.trace(\"Authenticating request using ClientCredentialsAuth.\")\n    if not self._access_token:\n        # Fetch token if not already available (first time or after expiry if implemented)\n        await self._fetch_access_token()\n\n    if not self._access_token:\n        # Should not happen if fetch was successful, but check anyway\n        raise AuthError(\"Authentication failed: Could not obtain access token.\")\n\n    request.headers[\"Authorization\"] = f\"Bearer {self._access_token}\"\n</code></pre>"},{"location":"auth/#bibliofabric.auth.ClientCredentialsAuth.async_close","title":"<code>async_close()</code>  <code>async</code>","text":"<p>Closes the internal HTTP client used for token fetching.</p> Source code in <code>src/bibliofabric/auth.py</code> <pre><code>async def async_close(self) -&gt; None:\n    \"\"\"Closes the internal HTTP client used for token fetching.\"\"\"\n    if self._token_client:\n        await self._token_client.aclose()\n        self._token_client = None\n        logger.debug(\"ClientCredentialsAuth internal client closed.\")\n</code></pre>"},{"location":"auth/#bibliofabric.auth.NoAuth","title":"<code>NoAuth</code>","text":"<p>Implements the AuthStrategy protocol for requests requiring no authentication.</p> <p>This strategy makes no modifications to the outgoing request.</p> Source code in <code>src/bibliofabric/auth.py</code> <pre><code>class NoAuth:\n    \"\"\"Implements the AuthStrategy protocol for requests requiring no authentication.\n\n    This strategy makes no modifications to the outgoing request.\n    \"\"\"\n\n    async def async_authenticate(self, request: httpx.Request) -&gt; None:\n        \"\"\"Does nothing as no authentication is needed.\"\"\"\n        logger.trace(\"Using NoAuth strategy, no authentication applied.\")\n\n    async def async_close(self) -&gt; None:\n        \"\"\"No resources to close for NoAuth, this method is a no-op.\"\"\"\n</code></pre>"},{"location":"auth/#bibliofabric.auth.NoAuth.async_authenticate","title":"<code>async_authenticate(request)</code>  <code>async</code>","text":"<p>Does nothing as no authentication is needed.</p> Source code in <code>src/bibliofabric/auth.py</code> <pre><code>async def async_authenticate(self, request: httpx.Request) -&gt; None:\n    \"\"\"Does nothing as no authentication is needed.\"\"\"\n    logger.trace(\"Using NoAuth strategy, no authentication applied.\")\n</code></pre>"},{"location":"auth/#bibliofabric.auth.NoAuth.async_close","title":"<code>async_close()</code>  <code>async</code>","text":"<p>No resources to close for NoAuth, this method is a no-op.</p> Source code in <code>src/bibliofabric/auth.py</code> <pre><code>async def async_close(self) -&gt; None:\n    \"\"\"No resources to close for NoAuth, this method is a no-op.\"\"\"\n</code></pre>"},{"location":"auth/#bibliofabric.auth.StaticTokenAuth","title":"<code>StaticTokenAuth</code>","text":"<p>Implements AuthStrategy using a static Bearer token.</p> <p>This strategy is suitable for APIs that use a pre-issued, long-lived API token (e.g., a personal access token). The token is added to the <code>Authorization</code> header as a Bearer token.</p> <p>Attributes:</p> Name Type Description <code>_token</code> <code>str</code> <p>The static API token.</p> Source code in <code>src/bibliofabric/auth.py</code> <pre><code>class StaticTokenAuth:\n    \"\"\"Implements AuthStrategy using a static Bearer token.\n\n    This strategy is suitable for APIs that use a pre-issued, long-lived\n    API token (e.g., a personal access token). The token is added to the\n    `Authorization` header as a Bearer token.\n\n    Attributes:\n        _token: The static API token.\n    \"\"\"\n\n    def __init__(self, token: str | None):\n        \"\"\"Initializes StaticTokenAuth with the provided API token.\n\n        Args:\n            token: The static API token to use for authentication.\n\n        Raises:\n            ConfigurationError: If the token is None or empty.\n        \"\"\"\n        if not token:\n            raise ConfigurationError(\"StaticTokenAuth requires a non-empty 'token'.\")\n        self._token: str = token\n        logger.debug(\"StaticTokenAuth initialized.\")\n\n    async def async_authenticate(self, request: httpx.Request) -&gt; None:\n        \"\"\"Adds the static 'Authorization: Bearer &lt;token&gt;' header to the request.\"\"\"\n        logger.trace(\"Authenticating request using StaticTokenAuth.\")\n        request.headers[\"Authorization\"] = f\"Bearer {self._token}\"\n\n    async def async_close(self) -&gt; None:\n        \"\"\"No resources to close for StaticTokenAuth, this method is a no-op.\"\"\"\n</code></pre>"},{"location":"auth/#bibliofabric.auth.StaticTokenAuth.__init__","title":"<code>__init__(token)</code>","text":"<p>Initializes StaticTokenAuth with the provided API token.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <code>str | None</code> <p>The static API token to use for authentication.</p> required <p>Raises:</p> Type Description <code>ConfigurationError</code> <p>If the token is None or empty.</p> Source code in <code>src/bibliofabric/auth.py</code> <pre><code>def __init__(self, token: str | None):\n    \"\"\"Initializes StaticTokenAuth with the provided API token.\n\n    Args:\n        token: The static API token to use for authentication.\n\n    Raises:\n        ConfigurationError: If the token is None or empty.\n    \"\"\"\n    if not token:\n        raise ConfigurationError(\"StaticTokenAuth requires a non-empty 'token'.\")\n    self._token: str = token\n    logger.debug(\"StaticTokenAuth initialized.\")\n</code></pre>"},{"location":"auth/#bibliofabric.auth.StaticTokenAuth.async_authenticate","title":"<code>async_authenticate(request)</code>  <code>async</code>","text":"<p>Adds the static 'Authorization: Bearer ' header to the request. Source code in <code>src/bibliofabric/auth.py</code> <pre><code>async def async_authenticate(self, request: httpx.Request) -&gt; None:\n    \"\"\"Adds the static 'Authorization: Bearer &lt;token&gt;' header to the request.\"\"\"\n    logger.trace(\"Authenticating request using StaticTokenAuth.\")\n    request.headers[\"Authorization\"] = f\"Bearer {self._token}\"\n</code></pre>"},{"location":"auth/#bibliofabric.auth.StaticTokenAuth.async_close","title":"<code>async_close()</code>  <code>async</code>","text":"<p>No resources to close for StaticTokenAuth, this method is a no-op.</p> Source code in <code>src/bibliofabric/auth.py</code> <pre><code>async def async_close(self) -&gt; None:\n    \"\"\"No resources to close for StaticTokenAuth, this method is a no-op.\"\"\"\n</code></pre>"},{"location":"client/","title":"Client","text":""},{"location":"client/#bibliofabric.client","title":"<code>bibliofabric.client</code>","text":"<p>Generic API client implementation for the bibliofabric framework.</p> <p>This module provides the BaseApiClient class, which contains all the generic HTTP client logic needed to build robust, asynchronous API clients. It handles retries, caching, rate limiting, authentication, and error handling in a completely API-agnostic way through the ResponseUnwrapper protocol.</p>"},{"location":"client/#bibliofabric.client.BaseApiClient","title":"<code>BaseApiClient</code>","text":"<p>Generic asynchronous HTTP client for interacting with APIs.</p> <p>This class provides a robust foundation for building API clients with built-in support for retries, caching, rate limiting, authentication, and error handling. It uses the ResponseUnwrapper protocol to enable API-agnostic response processing.</p> <p>The client is designed to be inherited by specific API implementations that provide their own ResponseUnwrapper and configure API-specific settings like base URLs and authentication strategies.</p> <p>Key features: - Automatic retries with exponential backoff for transient errors - Client-side caching for GET requests with configurable TTL - Rate limit detection and automatic throttling - Pluggable authentication strategies - Comprehensive error handling and logging - Pre/post request hooks for customization - Response unwrapping through the ResponseUnwrapper protocol</p> <p>Attributes:</p> Name Type Description <code>_settings</code> <p>Configuration settings for the client.</p> <code>_response_unwrapper</code> <p>Instance to handle API-specific response structures.</p> <code>_base_url</code> <code>str</code> <p>The base URL for API requests.</p> <code>_retryable_status_codes</code> <code>frozenset[int]</code> <p>HTTP status codes that trigger a retry.</p> <code>_cache</code> <code>TTLCache[str, Any] | None</code> <p>Optional TTL cache for GET requests.</p> <code>_auth_strategy</code> <code>AuthStrategy</code> <p>Authentication strategy instance.</p> <code>_http_client</code> <p>The underlying httpx.AsyncClient for making requests.</p> <code>_should_close_client</code> <p>Flag indicating if this instance owns the _http_client.</p> <code>_rate_limit_limit</code> <code>int | None</code> <p>Last observed rate limit capacity.</p> <code>_rate_limit_remaining</code> <code>int | None</code> <p>Last observed remaining requests in the current window.</p> <code>_rate_limit_reset_timestamp</code> <code>float | None</code> <p>Timestamp for when the rate limit window resets.</p> <code>_rate_limit_lock</code> <p>Lock for synchronizing access to rate limit state.</p> Source code in <code>src/bibliofabric/client.py</code> <pre><code>class BaseApiClient:\n    \"\"\"Generic asynchronous HTTP client for interacting with APIs.\n\n    This class provides a robust foundation for building API clients with built-in\n    support for retries, caching, rate limiting, authentication, and error handling.\n    It uses the ResponseUnwrapper protocol to enable API-agnostic response processing.\n\n    The client is designed to be inherited by specific API implementations that\n    provide their own ResponseUnwrapper and configure API-specific settings like\n    base URLs and authentication strategies.\n\n    Key features:\n    - Automatic retries with exponential backoff for transient errors\n    - Client-side caching for GET requests with configurable TTL\n    - Rate limit detection and automatic throttling\n    - Pluggable authentication strategies\n    - Comprehensive error handling and logging\n    - Pre/post request hooks for customization\n    - Response unwrapping through the ResponseUnwrapper protocol\n\n    Attributes:\n        _settings: Configuration settings for the client.\n        _response_unwrapper: Instance to handle API-specific response structures.\n        _base_url: The base URL for API requests.\n        _retryable_status_codes: HTTP status codes that trigger a retry.\n        _cache: Optional TTL cache for GET requests.\n        _auth_strategy: Authentication strategy instance.\n        _http_client: The underlying httpx.AsyncClient for making requests.\n        _should_close_client: Flag indicating if this instance owns the _http_client.\n        _rate_limit_limit: Last observed rate limit capacity.\n        _rate_limit_remaining: Last observed remaining requests in the current window.\n        _rate_limit_reset_timestamp: Timestamp for when the rate limit window resets.\n        _rate_limit_lock: Lock for synchronizing access to rate limit state.\n    \"\"\"\n\n    DEFAULT_RETRYABLE_STATUS_CODES: frozenset[int] = frozenset(\n        [429, 500, 502, 503, 504]\n    )\n    \"\"\"Default set of HTTP status codes considered retryable.\"\"\"\n\n    def __init__(\n        self,\n        settings: BaseApiSettings,\n        response_unwrapper: ResponseUnwrapper,\n        auth_strategy: AuthStrategy | None = None,\n        *,\n        base_url: str,\n        http_client: httpx.AsyncClient | None = None,\n        retryable_status_codes: frozenset[int] = DEFAULT_RETRYABLE_STATUS_CODES,\n    ):\n        \"\"\"Initialize the BaseApiClient.\n\n        Args:\n            settings: Configuration settings for the API client behavior.\n            response_unwrapper: Protocol implementation for handling API-specific\n                response structures and pagination.\n            auth_strategy: Optional authentication strategy. If None, uses NoAuth.\n            base_url: The base URL for API requests.\n            http_client: Optional pre-configured httpx.AsyncClient instance.\n            retryable_status_codes: Set of HTTP status codes to retry on.\n\n        Note:\n            The base_url should be provided by the specific API client implementation\n            and not hardcoded here to maintain the generic nature of this class.\n        \"\"\"\n        self._settings = settings\n        self._response_unwrapper = response_unwrapper\n        self._base_url: str = base_url.rstrip(\"/\")\n        self._retryable_status_codes: frozenset[int] = retryable_status_codes\n\n        # Initialize cache\n        self._cache: TTLCache[str, Any] | None = None\n        if self._settings.enable_caching and self._settings.cache_ttl_seconds &gt; 0:\n            logger.info(\n                f\"Client-side caching enabled. Max size: {self._settings.cache_max_size}, \"\n                f\"TTL: {self._settings.cache_ttl_seconds}s\"\n            )\n            self._cache = TTLCache(  # type: ignore[type-arg]\n                maxsize=self._settings.cache_max_size,\n                ttl=self._settings.cache_ttl_seconds,\n            )\n        else:\n            logger.info(\"Client-side caching is disabled.\")\n\n        # Set up authentication strategy\n        self._auth_strategy: AuthStrategy = auth_strategy or NoAuth()\n        logger.info(\n            f\"Using authentication strategy: {type(self._auth_strategy).__name__}\"\n        )\n\n        # HTTP client setup\n        self._should_close_client = http_client is None  # Close only if we created it\n        self._http_client = http_client or self._create_default_http_client()\n\n        # Rate limiting state\n        self._rate_limit_limit: int | None = None\n        self._rate_limit_remaining: int | None = None\n        self._rate_limit_reset_timestamp: float | None = None  # Unix timestamp\n        self._rate_limit_lock = asyncio.Lock()\n\n        logger.debug(\"BaseApiClient initialized.\")\n\n    def _create_default_http_client(self) -&gt; httpx.AsyncClient:\n        \"\"\"Create a default httpx.AsyncClient with configured settings.\n\n        Returns:\n            httpx.AsyncClient: Configured HTTP client with SSL verification,\n                timeout settings, and user agent header.\n        \"\"\"\n        try:\n            ssl_context = ssl.create_default_context(cafile=certifi.where())\n            verify_ssl = ssl_context\n            logger.debug(\"Using certifi SSL context.\")\n        except Exception:\n            verify_ssl = True\n            logger.warning(\n                \"certifi not found or failed to load. Using default SSL verification.\"\n            )\n\n        return httpx.AsyncClient(\n            base_url=self._base_url,\n            timeout=self._settings.request_timeout,\n            verify=verify_ssl,\n            headers={\"User-Agent\": self._settings.user_agent},\n        )\n\n    async def _parse_rate_limit_headers(self, response: httpx.Response) -&gt; float | None:\n        \"\"\"Parse rate limit headers from the response and update client state.\n\n        Args:\n            response: The HTTP response to parse headers from.\n\n        Returns:\n            float | None: The 'Retry-After' duration in seconds, if present.\n        \"\"\"\n        retry_after_seconds: float | None = None\n        async with self._rate_limit_lock:\n            try:\n                limit_str = response.headers.get(\"X-RateLimit-Limit\")\n                if limit_str and limit_str.isdigit():\n                    self._rate_limit_limit = int(limit_str)\n                    logger.debug(f\"Parsed X-RateLimit-Limit: {self._rate_limit_limit}\")\n\n                remaining_str = response.headers.get(\"X-RateLimit-Remaining\")\n                if remaining_str and remaining_str.isdigit():\n                    self._rate_limit_remaining = int(remaining_str)\n                    logger.debug(\n                        f\"Parsed X-RateLimit-Remaining: {self._rate_limit_remaining}\"\n                    )\n\n                reset_str = response.headers.get(\"X-RateLimit-Reset\")\n                if reset_str and reset_str.isdigit():\n                    self._rate_limit_reset_timestamp = float(reset_str)\n                    logger.debug(\n                        f\"Parsed X-RateLimit-Reset: {self._rate_limit_reset_timestamp}\"\n                    )\n                elif reset_str:  # Could be an HTTP date\n                    try:\n                        dt_reset_obj = parsedate_to_datetime(reset_str)\n                        self._rate_limit_reset_timestamp = dt_reset_obj.timestamp()\n                        logger.debug(\n                            f\"Parsed X-RateLimit-Reset (HTTP date): {self._rate_limit_reset_timestamp}\"\n                        )\n                    except Exception:\n                        logger.warning(\n                            f\"Could not parse X-RateLimit-Reset HTTP date: {reset_str}\"\n                        )\n\n                retry_after_header = response.headers.get(\"Retry-After\")\n                if retry_after_header:\n                    if retry_after_header.isdigit():\n                        retry_after_seconds = float(retry_after_header)\n                        logger.debug(\n                            f\"Parsed Retry-After (seconds): {retry_after_seconds}\"\n                        )\n                    else:\n                        try:\n                            # Attempt to parse as HTTP-date\n                            retry_dt_obj = parsedate_to_datetime(retry_after_header)\n                            # Ensure it's timezone-aware for correct comparison\n                            if (\n                                retry_dt_obj.tzinfo is None\n                                or retry_dt_obj.tzinfo.utcoffset(retry_dt_obj) is None\n                            ):\n                                logger.warning(\n                                    f\"Retry-After date '{retry_after_header}' is naive, assuming UTC.\"\n                                )\n                                retry_dt_obj = retry_dt_obj.replace(tzinfo=UTC)\n\n                            now_dt_obj = dt.now(UTC)\n                            delta = retry_dt_obj - now_dt_obj\n                            retry_after_seconds = max(0, delta.total_seconds())\n                            logger.debug(\n                                f\"Parsed Retry-After (HTTP date): {retry_after_header}, calculated seconds: {retry_after_seconds}\"\n                            )\n                        except Exception as e:\n                            logger.warning(\n                                f\"Could not parse Retry-After HTTP date '{retry_after_header}': {e}\"\n                            )\n            except Exception as e:\n                logger.exception(f\"Error parsing rate limit headers: {e}\")\n        return retry_after_seconds\n\n    async def _execute_single_request(\n        self, request_data: RequestData, expected_model: type[Any] | None = None\n    ) -&gt; tuple[httpx.Response, Any | None]:\n        \"\"\"Execute a single HTTP request attempt, run hooks, and parse if model provided.\n\n        Args:\n            request_data: The request data including method, URL, params, etc.\n            expected_model: Optional Pydantic model class for response validation.\n\n        Returns:\n            tuple[httpx.Response, Any | None]: The HTTP response and optionally\n                parsed model instance if expected_model was provided and parsing succeeded.\n\n        Raises:\n            RateLimitError: If API rate limit is exceeded (429 status).\n            APIError: For other HTTP error responses (4xx/5xx).\n            TimeoutError: If the request times out.\n            NetworkError: For network-related errors.\n            BibliofabricError: For other unexpected errors.\n        \"\"\"\n        # --- Pre-Request Hooks ---\n        # Prepare mutable versions of params and headers for hooks\n        hook_params: dict[str, Any] | None = (\n            dict(request_data.params) if request_data.params is not None else None\n        )\n        hook_headers: httpx.Headers = httpx.Headers(request_data.headers)\n\n        if self._settings.pre_request_hooks:\n            logger.debug(\n                f\"Executing {len(self._settings.pre_request_hooks)} pre-request hooks \"\n                f\"for {request_data.method} {request_data.url}\"\n            )\n            for hook in self._settings.pre_request_hooks:\n                try:\n                    hook(\n                        request_data.method,\n                        request_data.url,\n                        hook_params,\n                        hook_headers,\n                    )\n                except Exception as e:\n                    logger.error(\n                        f\"Error executing pre-request hook {getattr(hook, '__name__', str(hook))}: {e}\",\n                        exc_info=True,\n                    )\n\n            # Update request_data from potentially modified hook_params and hook_headers\n            request_data.params = hook_params\n            # Convert modified hook_headers (httpx.Headers) back to a dict for request_data.headers\n            request_data.headers = {k: v for k, v in hook_headers.items()}\n\n        request = request_data.build_request()\n        response: httpx.Response | None = None\n        parsed_model: Any | None = None\n        retry_after_from_headers: float | None = None\n\n        try:\n            # Apply authentication just before sending\n            await self._auth_strategy.async_authenticate(request)\n\n            # Ensure User-Agent is set\n            if \"User-Agent\" not in request.headers or not request.headers[\"User-Agent\"]:\n                request.headers[\"User-Agent\"] = self._settings.user_agent\n\n            logger.debug(f\"Sending request: {request.method} {request.url}\")\n            logger.trace(f\"Request Headers: {request.headers}\")\n            if request.content:\n                logger.trace(f\"Request Body: {request.content.decode()}\")\n\n            response = await self._http_client.send(request)\n            retry_after_from_headers = await self._parse_rate_limit_headers(response)\n\n            logger.debug(f\"Received response: {response.status_code} for {request.url}\")\n            logger.trace(f\"Response Headers: {response.headers}\")\n\n            if response.status_code &gt;= HTTPStatus.BAD_REQUEST:\n                if response.status_code == HTTPStatus.TOO_MANY_REQUESTS:\n                    if self._settings.enable_rate_limiting:\n                        wait_duration = (\n                            retry_after_from_headers\n                            or self._settings.rate_limit_retry_after_default\n                        )\n                        logger.info(\n                            f\"Rate limit hit (429). Raising RateLimitError. Retry will be handled by tenacity with appropriate wait. Wait duration hint from server: {wait_duration:.2f}s. Client open: {not self._http_client.is_closed if self._http_client else 'N/A'}\"\n                        )\n                    logger.error(\n                        f\"Raising RateLimitError after 429. Client open: {not self._http_client.is_closed if self._http_client else 'N/A'}\"\n                    )\n                    raise RateLimitError(\"API rate limit exceeded.\", response=response)\n                raise APIError(\n                    f\"API request failed with status {response.status_code}\",\n                    response=response,\n                )\n\n            # Successful response, try parsing if expected_model is provided\n            if expected_model:\n                try:\n                    parsed_model = expected_model.model_validate(response.json())\n                except Exception as e:\n                    logger.warning(\n                        f\"Response model validation failed for {request.url}: {e}. \"\n                        \"Parsed model will be None.\"\n                    )\n                    # parsed_model remains None\n\n            # --- Post-Request Hooks ---\n            if self._settings.post_request_hooks:\n                logger.debug(\n                    f\"Executing {len(self._settings.post_request_hooks)} post-request hooks \"\n                    f\"for {request.method} {request.url}\"\n                )\n                for hook in self._settings.post_request_hooks:\n                    try:\n                        hook(response, parsed_model, 1)  # Always 1 for single request\n                    except Exception as e:\n                        logger.error(\n                            f\"Error executing post-request hook {getattr(hook, '__name__', str(hook))}: {e}\",\n                            exc_info=True,\n                        )\n\n            return response, parsed_model\n\n        except httpx.HTTPStatusError as e:\n            # This block might be hit if httpx raises before our status check\n            if e.response:\n                retry_after_from_headers = await self._parse_rate_limit_headers(\n                    e.response\n                )\n\n            logger.error(\n                f\"Request failed with status {e.response.status_code}: {e.request.url}\"\n            )\n            if e.response.status_code == HTTPStatus.TOO_MANY_REQUESTS:\n                if self._settings.enable_rate_limiting:\n                    wait_duration = (\n                        retry_after_from_headers\n                        or self._settings.rate_limit_retry_after_default\n                    )\n                    logger.info(\n                        f\"Rate limit hit (429) in HTTPStatusError. Waiting for {wait_duration:.2f}s.\"\n                    )\n                    await asyncio.sleep(wait_duration)\n                raise RateLimitError(\n                    \"API rate limit exceeded.\", response=e.response, request=e.request\n                ) from e\n            raise APIError(\n                f\"API request failed with status {e.response.status_code}\",\n                response=e.response,\n                request=e.request,\n            ) from e\n        except httpx.TimeoutException as e:\n            logger.error(f\"Request timed out: {request.url}\")\n            raise TimeoutError(\"Request timed out\", request=request) from e\n        except httpx.NetworkError as e:  # Specific network errors\n            logger.error(f\"Network error occurred for {request.url}: {e}\")\n            raise NetworkError(\n                f\"Network error for {request.url}: {e}\", request=request\n            ) from e\n        except httpx.RequestError as e:  # Other httpx request errors (e.g. connection, read timeouts if not httpx.TimeoutException)\n            logger.error(f\"HTTP request error for {request.url}: {e}\")\n            raise BibliofabricRequestError(\n                f\"HTTP request error for {request.url}: {e}\", request=request\n            ) from e\n        except Exception as e:\n            # If response was received before another exception, parse its headers\n            if response:\n                await self._parse_rate_limit_headers(response)\n\n            logger.exception(\n                f\"Unexpected error during single request execution to {request.url}: {e}\"\n            )\n            if isinstance(e, BibliofabricError):  # If it's already our error, re-raise\n                raise e\n            # Keep this as a general fallback\n            raise BibliofabricError(\n                f\"An unexpected error occurred during request execution: {e}\",\n                request=request,\n            ) from e\n\n    def _should_retry_request(self, retry_state: tenacity.RetryCallState) -&gt; bool:\n        \"\"\"Predicate for tenacity: should we retry this request?\n\n        Args:\n            retry_state: The current retry state from tenacity.\n\n        Returns:\n            bool: True if the request should be retried, False otherwise.\n        \"\"\"\n        outcome = retry_state.outcome\n        if not outcome:  # Should not happen with reraise=True, but defensive check\n            return False\n\n        if outcome.failed:\n            exc = outcome.exception()\n            url = \"N/A\"\n            request = getattr(exc, \"request\", None)\n            if request:\n                url = str(getattr(request, \"url\", \"N/A\"))\n\n            # Retry on timeout, network, and rate limit errors\n            if isinstance(exc, TimeoutError | NetworkError | RateLimitError):\n                logger.warning(f\"Retrying due to {type(exc).__name__} for {url}\")\n                return True\n            # Also retry on httpx exceptions\n            if isinstance(exc, httpx.TimeoutException | httpx.NetworkError):\n                logger.warning(\n                    f\"Retrying due to {type(exc).__name__} (httpx) for {url}\"\n                )\n                return True\n\n            status_code: int | None = None\n            if isinstance(exc, APIError):\n                if exc.response is not None:\n                    status_code = exc.response.status_code\n            elif isinstance(exc, httpx.HTTPStatusError):\n                status_code = exc.response.status_code\n\n            if status_code is not None and status_code in self._retryable_status_codes:\n                logger.warning(f\"Retrying due to status code {status_code} for {url}\")\n                return True\n\n        return False\n\n    async def _request_with_retry(\n        self,\n        method: str,\n        path: str,\n        params: Mapping[str, Any] | None = None,\n        json_data: Any | None = None,\n        data: Mapping[str, Any] | None = None,\n        base_url_override: str | None = None,\n        expected_model: type[Any] | None = None,\n    ) -&gt; tuple[httpx.Response, Any | None, int]:\n        \"\"\"Make an HTTP request with configured retries for transient errors.\n\n        Args:\n            method: HTTP method (GET, POST, etc.).\n            path: Request path relative to base URL.\n            params: Query parameters.\n            json_data: JSON data for request body.\n            data: Form data for request body.\n            base_url_override: Optional override for the base URL.\n            expected_model: Optional Pydantic model for response parsing.\n\n        Returns:\n            tuple[httpx.Response, Any | None, int]: The HTTP response, optionally\n                parsed model instance, and the number of attempts made.\n\n        Raises:\n            Various exceptions depending on failure type after all retries are exhausted.\n        \"\"\"\n        # Determine the correct base URL for this request\n        _target_base_url = (base_url_override or self._base_url).rstrip(\"/\")\n        full_url = f\"{_target_base_url}/{path.lstrip('/')}\"\n\n        request_data = RequestData(\n            method=method,\n            url=full_url,\n            params=params,\n            json_data=json_data,\n            data=data,\n            # Headers will be populated by auth strategy and pre-request hooks\n        )\n\n        # Pre-request rate limit check\n        if self._settings.enable_rate_limiting:\n            async with self._rate_limit_lock:\n                # Check if we have rate limit information\n                if (\n                    self._rate_limit_remaining is not None\n                    and self._rate_limit_limit is not None\n                    and self._rate_limit_limit &gt; 0\n                ):\n                    # Check if remaining requests are below the buffer or zero\n                    buffer_threshold = (\n                        self._rate_limit_limit\n                        * self._settings.rate_limit_buffer_percentage\n                    )\n                    if (\n                        self._rate_limit_remaining &lt;= buffer_threshold\n                        or self._rate_limit_remaining == 0\n                    ):\n                        if self._rate_limit_reset_timestamp is not None:\n                            current_time = time.time()\n                            wait_time = self._rate_limit_reset_timestamp - current_time\n                            if wait_time &gt; 0:\n                                logger.info(\n                                    f\"Rate limit approaching/reached. \"\n                                    f\"Remaining: {self._rate_limit_remaining}/{self._rate_limit_limit}. \"\n                                    f\"Waiting for {wait_time:.2f}s until reset.\"\n                                )\n                                await asyncio.sleep(wait_time)\n                        elif self._rate_limit_remaining == 0:\n                            logger.warning(\n                                f\"Rate limit reset time {self._rate_limit_reset_timestamp} is past \"\n                                f\"but remaining requests is {self._rate_limit_remaining}. \"\n                                f\"Waiting for default: {self._settings.rate_limit_retry_after_default}s.\"\n                            )\n                            await asyncio.sleep(\n                                self._settings.rate_limit_retry_after_default\n                            )\n                elif self._rate_limit_remaining == 0 and self._rate_limit_limit is None:\n                    # If remaining is 0 (e.g. from a 429) but we never got a limit header\n                    logger.warning(\n                        f\"Rate limit remaining is 0 (likely from a 429) but no limit/reset headers were ever parsed. \"\n                        f\"Waiting for default: {self._settings.rate_limit_retry_after_default}s as a precaution.\"\n                    )\n                    await asyncio.sleep(self._settings.rate_limit_retry_after_default)\n\n        # Apply authentication *before* retry loop setup, fail fast on auth issues\n        try:\n            # Build a temporary request to apply auth and get initial headers\n            temp_request_for_auth = request_data.build_request()\n            await self._auth_strategy.async_authenticate(temp_request_for_auth)\n            # Update request_data.headers with those from the auth strategy\n            request_data.headers = dict(temp_request_for_auth.headers)\n        except AuthError as e:\n            logger.error(f\"Authentication failed before request: {e}\")\n            raise e\n        except Exception as e:\n            logger.exception(f\"Unexpected error during pre-request authentication: {e}\")\n            raise BibliofabricError(f\"Unexpected authentication error: {e}\") from e\n\n        # Prepare retry strategy\n        retry_strategy = AsyncRetrying(\n            stop=stop_after_attempt(\n                self._settings.max_retries + 1\n            ),  # +1 for initial attempt\n            wait=wait_exponential(\n                multiplier=self._settings.backoff_factor,\n            ),\n            retry=self._should_retry_request,\n            reraise=True,  # Reraise the exception if all retries fail\n            before_sleep=self._before_retry_sleep,  # Log before sleeping\n        )\n\n        try:\n            response, parsed_model = await retry_strategy(\n                self._execute_single_request, request_data, expected_model\n            )\n            return response, parsed_model, retry_strategy.statistics[\"attempt_number\"]\n        except Exception as e:\n            logger.error(f\"Request failed after multiple retries: {e}\")\n            raise\n\n    async def _before_retry_sleep(self, retry_state: tenacity.RetryCallState) -&gt; None:\n        \"\"\"Log details before tenacity sleeps between retries.\n\n        Args:\n            retry_state: The current retry state from tenacity.\n        \"\"\"\n        if not retry_state.outcome:  # Should not happen\n            return\n\n        exc = retry_state.outcome.exception()\n        url = \"N/A\"\n        request_info = \"\"\n        if exc and hasattr(exc, \"request\") and getattr(exc, \"request\", None):\n            request = getattr(exc, \"request\", None)\n            if request:\n                url = str(getattr(request, \"url\", \"N/A\"))\n                method = str(getattr(request, \"method\", \"N/A\"))\n                request_info = f\"for {method} {url}\"\n\n        sleep_time = (\n            getattr(retry_state.next_action, \"sleep\", 0)\n            if retry_state.next_action\n            else 0\n        )\n        logger.info(\n            f\"Retrying request {request_info} in {sleep_time:.2f} seconds \"\n            f\"after {retry_state.attempt_number} attempt(s) due to: {type(exc).__name__} - {exc}\"\n        )\n\n    def _generate_cache_key(\n        self, method: str, url: str, params: Mapping[str, Any] | None = None\n    ) -&gt; str:\n        \"\"\"Generate a cache key from the request method, URL, and parameters.\n\n        Args:\n            method: HTTP method (e.g., 'GET', 'POST').\n            url: Full URL for the request.\n            params: Query parameters dict.\n\n        Returns:\n            str: A unique cache key string.\n        \"\"\"\n\n        # Start with method and URL\n        key_parts = [method.upper(), url]\n\n        # Add sorted parameters if they exist\n        if params:\n            # Sort parameters to ensure consistent cache keys\n            sorted_params = json.dumps(params, sort_keys=True, separators=(\",\", \":\"))\n            key_parts.append(sorted_params)\n\n        # Create a hash of the combined key parts\n        cache_key_string = \"|\".join(key_parts)\n        return hashlib.md5(cache_key_string.encode(\"utf-8\")).hexdigest()\n\n    async def request(\n        self,\n        method: str,\n        path: str,\n        *,\n        params: Mapping[str, Any] | None = None,\n        json: Any | None = None,  # Alias for json_data\n        json_data: Any | None = None,\n        data: Mapping[str, Any] | None = None,\n        expected_model: type[Any] | None = None,\n        base_url_override: str | None = None,\n    ) -&gt; httpx.Response | Any:\n        \"\"\"Perform an asynchronous HTTP request to the specified API path.\n\n        This method provides the main interface for making API requests with automatic\n        retries, caching (for GET requests), rate limiting, and error handling.\n\n        Args:\n            method: HTTP method (GET, POST, PUT, DELETE, etc.).\n            path: Request path relative to the base URL.\n            params: Query parameters as a mapping.\n            json: JSON data for request body (alias for json_data).\n            json_data: JSON data for request body.\n            data: Form data for request body.\n            expected_model: Optional Pydantic model class for response validation.\n            base_url_override: Optional override for the base URL.\n\n        Returns:\n            httpx.Response | Any: Raw httpx.Response if no expected_model provided,\n                otherwise the parsed Pydantic model instance, falling back to\n                raw response if parsing fails.\n\n        Note:\n            GET requests are automatically cached when caching is enabled and\n            an expected_model is provided. Cache hits return the parsed model\n            directly without making an HTTP request.\n        \"\"\"\n        actual_json_data = json_data if json_data is not None else json\n        if json is not None and json_data is not None:\n            logger.warning(\n                \"Both 'json' and 'json_data' provided to request; using 'json_data'.\"\n            )\n\n        cache_key: str | None = None\n\n        # --- Cache Check (for GET requests) ---\n        if self._cache is not None and method.upper() == \"GET\":\n            _target_base_url = (base_url_override or self._base_url).rstrip(\"/\")\n            full_url = f\"{_target_base_url}/{path.lstrip('/')}\"\n            cache_key = self._generate_cache_key(method, full_url, params)\n\n            cached_item = self._cache.get(cache_key)\n            if cached_item is not None:\n                # Assuming the cached item is the already parsed Pydantic model\n                logger.debug(f\"Cache hit for key: {cache_key}\")\n                if expected_model and not isinstance(cached_item, expected_model):\n                    logger.warning(\n                        f\"Cache hit for {cache_key}, but type mismatch. \"\n                        f\"Expected {expected_model}, got {type(cached_item)}. Discarding cache.\"\n                    )\n                    self._cache.pop(cache_key, None)  # Treat as cache miss\n                else:\n                    logger.debug(f\"Returning cached parsed model for key: {cache_key}\")\n                    return cached_item  # cached_item is the parsed_model\n\n        # --- Execute Request (if not a cache hit or not cacheable) ---\n        response, parsed_model, attempts = await self._request_with_retry(\n            method=method,\n            path=path,\n            params=params,\n            json_data=actual_json_data,\n            data=data,\n            base_url_override=base_url_override,\n            expected_model=expected_model,\n        )\n\n        # --- Cache Store (for successful GET requests with a successfully parsed model) ---\n        if (\n            self._cache is not None\n            and cache_key is not None  # Implies GET and cache enabled\n            and method.upper() == \"GET\"\n            and HTTPStatus.OK\n            &lt;= response.status_code\n            &lt; HTTPStatus.MULTIPLE_CHOICES  # 2xx\n        ):\n            if expected_model and parsed_model is not None:\n                # Ensure what we are caching is indeed of the expected_model type\n                if isinstance(parsed_model, expected_model):\n                    self._cache[cache_key] = (\n                        parsed_model  # Store the already parsed model\n                    )\n                    logger.debug(f\"Cached parsed model for key: {cache_key}\")\n                else:\n                    logger.warning(\n                        f\"Attempted to cache for key {cache_key}, but parsed_model type \"\n                        f\"{type(parsed_model)} does not match expected_model {expected_model}. Not caching.\"\n                    )\n            elif expected_model and parsed_model is None:\n                logger.debug(\n                    f\"GET request for {cache_key} successful, but model parsing failed or no model to parse. Not caching.\"\n                )\n\n        # --- Standard Response Handling ---\n        if expected_model:\n            if parsed_model is not None and isinstance(parsed_model, expected_model):\n                return parsed_model  # Return the successfully parsed model\n            # Parsing failed inside _execute_single_request (parsed_model is None)\n            # or it's not of the expected type (should be rare if parsing succeeded).\n            logger.warning(\n                f\"Expected model {expected_model.__name__} but parsing failed, model was None, \"\n                f\"or type mismatch for {method} {path}. Returning raw response.\"\n            )\n            return response  # Fallback to raw response\n\n        return response  # Default: return raw response if no expected_model\n\n    async def aclose(self) -&gt; None:\n        \"\"\"Close the underlying HTTP client and any auth-specific clients.\n\n        This method should be called when the client is no longer needed to\n        properly clean up resources like HTTP connections and authentication\n        clients.\n        \"\"\"\n        logger.info(\n            f\"BaseApiClient.aclose() called. Client ID: {id(self)}. HTTP client to close: {self._should_close_client and self._http_client is not None}. HTTP client closed: {self._http_client.is_closed if self._http_client else 'N/A'}\"\n        )\n        if (\n            self._should_close_client\n            and self._http_client\n            and not self._http_client.is_closed\n        ):\n            await self._http_client.aclose()\n            logger.info(\n                f\"BaseApiClient internal HTTP client closed. Client ID: {id(self)}.\"\n            )\n        elif self._http_client and self._http_client.is_closed:\n            logger.info(\n                f\"BaseApiClient.aclose(): HTTP client was already closed. Client ID: {id(self)}\"\n            )\n        # Close auth strategy client if it has an async_close method\n        if hasattr(self._auth_strategy, \"async_close\") and callable(\n            self._auth_strategy.async_close\n        ):\n            await self._auth_strategy.async_close()  # type: ignore\n\n    async def __aenter__(self) -&gt; Self:\n        \"\"\"Enter the async context manager.\n\n        Returns:\n            Self: The client instance for use in async context.\n        \"\"\"\n        logger.info(\n            f\"BaseApiClient.__aenter__() called. Client ID: {id(self)}. HTTP client closed: {self._http_client.is_closed if self._http_client else 'N/A'}\"\n        )\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: object | None,\n    ) -&gt; None:\n        \"\"\"Exit the async context manager and clean up resources.\n\n        Args:\n            exc_type: Exception type if an exception occurred.\n            exc_val: Exception value if an exception occurred.\n            exc_tb: Exception traceback if an exception occurred.\n        \"\"\"\n        logger.info(\n            f\"BaseApiClient.__aexit__() called. Client ID: {id(self)}. HTTP client closed before aclose: {self._http_client.is_closed if self._http_client else 'N/A'}\"\n        )\n        await self.aclose()\n        logger.info(\n            f\"BaseApiClient.__aexit__() finished. Client ID: {id(self)}. HTTP client closed after aclose: {self._http_client.is_closed if self._http_client else 'N/A'}\"\n        )\n</code></pre>"},{"location":"client/#bibliofabric.client.BaseApiClient.DEFAULT_RETRYABLE_STATUS_CODES","title":"<code>DEFAULT_RETRYABLE_STATUS_CODES = frozenset([429, 500, 502, 503, 504])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Default set of HTTP status codes considered retryable.</p>"},{"location":"client/#bibliofabric.client.BaseApiClient.__aenter__","title":"<code>__aenter__()</code>  <code>async</code>","text":"<p>Enter the async context manager.</p> <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>The client instance for use in async context.</p> Source code in <code>src/bibliofabric/client.py</code> <pre><code>async def __aenter__(self) -&gt; Self:\n    \"\"\"Enter the async context manager.\n\n    Returns:\n        Self: The client instance for use in async context.\n    \"\"\"\n    logger.info(\n        f\"BaseApiClient.__aenter__() called. Client ID: {id(self)}. HTTP client closed: {self._http_client.is_closed if self._http_client else 'N/A'}\"\n    )\n    return self\n</code></pre>"},{"location":"client/#bibliofabric.client.BaseApiClient.__aexit__","title":"<code>__aexit__(exc_type, exc_val, exc_tb)</code>  <code>async</code>","text":"<p>Exit the async context manager and clean up resources.</p> <p>Parameters:</p> Name Type Description Default <code>exc_type</code> <code>type[BaseException] | None</code> <p>Exception type if an exception occurred.</p> required <code>exc_val</code> <code>BaseException | None</code> <p>Exception value if an exception occurred.</p> required <code>exc_tb</code> <code>object | None</code> <p>Exception traceback if an exception occurred.</p> required Source code in <code>src/bibliofabric/client.py</code> <pre><code>async def __aexit__(\n    self,\n    exc_type: type[BaseException] | None,\n    exc_val: BaseException | None,\n    exc_tb: object | None,\n) -&gt; None:\n    \"\"\"Exit the async context manager and clean up resources.\n\n    Args:\n        exc_type: Exception type if an exception occurred.\n        exc_val: Exception value if an exception occurred.\n        exc_tb: Exception traceback if an exception occurred.\n    \"\"\"\n    logger.info(\n        f\"BaseApiClient.__aexit__() called. Client ID: {id(self)}. HTTP client closed before aclose: {self._http_client.is_closed if self._http_client else 'N/A'}\"\n    )\n    await self.aclose()\n    logger.info(\n        f\"BaseApiClient.__aexit__() finished. Client ID: {id(self)}. HTTP client closed after aclose: {self._http_client.is_closed if self._http_client else 'N/A'}\"\n    )\n</code></pre>"},{"location":"client/#bibliofabric.client.BaseApiClient.__init__","title":"<code>__init__(settings, response_unwrapper, auth_strategy=None, *, base_url, http_client=None, retryable_status_codes=DEFAULT_RETRYABLE_STATUS_CODES)</code>","text":"<p>Initialize the BaseApiClient.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>BaseApiSettings</code> <p>Configuration settings for the API client behavior.</p> required <code>response_unwrapper</code> <code>ResponseUnwrapper</code> <p>Protocol implementation for handling API-specific response structures and pagination.</p> required <code>auth_strategy</code> <code>AuthStrategy | None</code> <p>Optional authentication strategy. If None, uses NoAuth.</p> <code>None</code> <code>base_url</code> <code>str</code> <p>The base URL for API requests.</p> required <code>http_client</code> <code>AsyncClient | None</code> <p>Optional pre-configured httpx.AsyncClient instance.</p> <code>None</code> <code>retryable_status_codes</code> <code>frozenset[int]</code> <p>Set of HTTP status codes to retry on.</p> <code>DEFAULT_RETRYABLE_STATUS_CODES</code> Note <p>The base_url should be provided by the specific API client implementation and not hardcoded here to maintain the generic nature of this class.</p> Source code in <code>src/bibliofabric/client.py</code> <pre><code>def __init__(\n    self,\n    settings: BaseApiSettings,\n    response_unwrapper: ResponseUnwrapper,\n    auth_strategy: AuthStrategy | None = None,\n    *,\n    base_url: str,\n    http_client: httpx.AsyncClient | None = None,\n    retryable_status_codes: frozenset[int] = DEFAULT_RETRYABLE_STATUS_CODES,\n):\n    \"\"\"Initialize the BaseApiClient.\n\n    Args:\n        settings: Configuration settings for the API client behavior.\n        response_unwrapper: Protocol implementation for handling API-specific\n            response structures and pagination.\n        auth_strategy: Optional authentication strategy. If None, uses NoAuth.\n        base_url: The base URL for API requests.\n        http_client: Optional pre-configured httpx.AsyncClient instance.\n        retryable_status_codes: Set of HTTP status codes to retry on.\n\n    Note:\n        The base_url should be provided by the specific API client implementation\n        and not hardcoded here to maintain the generic nature of this class.\n    \"\"\"\n    self._settings = settings\n    self._response_unwrapper = response_unwrapper\n    self._base_url: str = base_url.rstrip(\"/\")\n    self._retryable_status_codes: frozenset[int] = retryable_status_codes\n\n    # Initialize cache\n    self._cache: TTLCache[str, Any] | None = None\n    if self._settings.enable_caching and self._settings.cache_ttl_seconds &gt; 0:\n        logger.info(\n            f\"Client-side caching enabled. Max size: {self._settings.cache_max_size}, \"\n            f\"TTL: {self._settings.cache_ttl_seconds}s\"\n        )\n        self._cache = TTLCache(  # type: ignore[type-arg]\n            maxsize=self._settings.cache_max_size,\n            ttl=self._settings.cache_ttl_seconds,\n        )\n    else:\n        logger.info(\"Client-side caching is disabled.\")\n\n    # Set up authentication strategy\n    self._auth_strategy: AuthStrategy = auth_strategy or NoAuth()\n    logger.info(\n        f\"Using authentication strategy: {type(self._auth_strategy).__name__}\"\n    )\n\n    # HTTP client setup\n    self._should_close_client = http_client is None  # Close only if we created it\n    self._http_client = http_client or self._create_default_http_client()\n\n    # Rate limiting state\n    self._rate_limit_limit: int | None = None\n    self._rate_limit_remaining: int | None = None\n    self._rate_limit_reset_timestamp: float | None = None  # Unix timestamp\n    self._rate_limit_lock = asyncio.Lock()\n\n    logger.debug(\"BaseApiClient initialized.\")\n</code></pre>"},{"location":"client/#bibliofabric.client.BaseApiClient.aclose","title":"<code>aclose()</code>  <code>async</code>","text":"<p>Close the underlying HTTP client and any auth-specific clients.</p> <p>This method should be called when the client is no longer needed to properly clean up resources like HTTP connections and authentication clients.</p> Source code in <code>src/bibliofabric/client.py</code> <pre><code>async def aclose(self) -&gt; None:\n    \"\"\"Close the underlying HTTP client and any auth-specific clients.\n\n    This method should be called when the client is no longer needed to\n    properly clean up resources like HTTP connections and authentication\n    clients.\n    \"\"\"\n    logger.info(\n        f\"BaseApiClient.aclose() called. Client ID: {id(self)}. HTTP client to close: {self._should_close_client and self._http_client is not None}. HTTP client closed: {self._http_client.is_closed if self._http_client else 'N/A'}\"\n    )\n    if (\n        self._should_close_client\n        and self._http_client\n        and not self._http_client.is_closed\n    ):\n        await self._http_client.aclose()\n        logger.info(\n            f\"BaseApiClient internal HTTP client closed. Client ID: {id(self)}.\"\n        )\n    elif self._http_client and self._http_client.is_closed:\n        logger.info(\n            f\"BaseApiClient.aclose(): HTTP client was already closed. Client ID: {id(self)}\"\n        )\n    # Close auth strategy client if it has an async_close method\n    if hasattr(self._auth_strategy, \"async_close\") and callable(\n        self._auth_strategy.async_close\n    ):\n        await self._auth_strategy.async_close()  # type: ignore\n</code></pre>"},{"location":"client/#bibliofabric.client.BaseApiClient.request","title":"<code>request(method, path, *, params=None, json=None, json_data=None, data=None, expected_model=None, base_url_override=None)</code>  <code>async</code>","text":"<p>Perform an asynchronous HTTP request to the specified API path.</p> <p>This method provides the main interface for making API requests with automatic retries, caching (for GET requests), rate limiting, and error handling.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>HTTP method (GET, POST, PUT, DELETE, etc.).</p> required <code>path</code> <code>str</code> <p>Request path relative to the base URL.</p> required <code>params</code> <code>Mapping[str, Any] | None</code> <p>Query parameters as a mapping.</p> <code>None</code> <code>json</code> <code>Any | None</code> <p>JSON data for request body (alias for json_data).</p> <code>None</code> <code>json_data</code> <code>Any | None</code> <p>JSON data for request body.</p> <code>None</code> <code>data</code> <code>Mapping[str, Any] | None</code> <p>Form data for request body.</p> <code>None</code> <code>expected_model</code> <code>type[Any] | None</code> <p>Optional Pydantic model class for response validation.</p> <code>None</code> <code>base_url_override</code> <code>str | None</code> <p>Optional override for the base URL.</p> <code>None</code> <p>Returns:</p> Type Description <code>Response | Any</code> <p>httpx.Response | Any: Raw httpx.Response if no expected_model provided, otherwise the parsed Pydantic model instance, falling back to raw response if parsing fails.</p> Note <p>GET requests are automatically cached when caching is enabled and an expected_model is provided. Cache hits return the parsed model directly without making an HTTP request.</p> Source code in <code>src/bibliofabric/client.py</code> <pre><code>async def request(\n    self,\n    method: str,\n    path: str,\n    *,\n    params: Mapping[str, Any] | None = None,\n    json: Any | None = None,  # Alias for json_data\n    json_data: Any | None = None,\n    data: Mapping[str, Any] | None = None,\n    expected_model: type[Any] | None = None,\n    base_url_override: str | None = None,\n) -&gt; httpx.Response | Any:\n    \"\"\"Perform an asynchronous HTTP request to the specified API path.\n\n    This method provides the main interface for making API requests with automatic\n    retries, caching (for GET requests), rate limiting, and error handling.\n\n    Args:\n        method: HTTP method (GET, POST, PUT, DELETE, etc.).\n        path: Request path relative to the base URL.\n        params: Query parameters as a mapping.\n        json: JSON data for request body (alias for json_data).\n        json_data: JSON data for request body.\n        data: Form data for request body.\n        expected_model: Optional Pydantic model class for response validation.\n        base_url_override: Optional override for the base URL.\n\n    Returns:\n        httpx.Response | Any: Raw httpx.Response if no expected_model provided,\n            otherwise the parsed Pydantic model instance, falling back to\n            raw response if parsing fails.\n\n    Note:\n        GET requests are automatically cached when caching is enabled and\n        an expected_model is provided. Cache hits return the parsed model\n        directly without making an HTTP request.\n    \"\"\"\n    actual_json_data = json_data if json_data is not None else json\n    if json is not None and json_data is not None:\n        logger.warning(\n            \"Both 'json' and 'json_data' provided to request; using 'json_data'.\"\n        )\n\n    cache_key: str | None = None\n\n    # --- Cache Check (for GET requests) ---\n    if self._cache is not None and method.upper() == \"GET\":\n        _target_base_url = (base_url_override or self._base_url).rstrip(\"/\")\n        full_url = f\"{_target_base_url}/{path.lstrip('/')}\"\n        cache_key = self._generate_cache_key(method, full_url, params)\n\n        cached_item = self._cache.get(cache_key)\n        if cached_item is not None:\n            # Assuming the cached item is the already parsed Pydantic model\n            logger.debug(f\"Cache hit for key: {cache_key}\")\n            if expected_model and not isinstance(cached_item, expected_model):\n                logger.warning(\n                    f\"Cache hit for {cache_key}, but type mismatch. \"\n                    f\"Expected {expected_model}, got {type(cached_item)}. Discarding cache.\"\n                )\n                self._cache.pop(cache_key, None)  # Treat as cache miss\n            else:\n                logger.debug(f\"Returning cached parsed model for key: {cache_key}\")\n                return cached_item  # cached_item is the parsed_model\n\n    # --- Execute Request (if not a cache hit or not cacheable) ---\n    response, parsed_model, attempts = await self._request_with_retry(\n        method=method,\n        path=path,\n        params=params,\n        json_data=actual_json_data,\n        data=data,\n        base_url_override=base_url_override,\n        expected_model=expected_model,\n    )\n\n    # --- Cache Store (for successful GET requests with a successfully parsed model) ---\n    if (\n        self._cache is not None\n        and cache_key is not None  # Implies GET and cache enabled\n        and method.upper() == \"GET\"\n        and HTTPStatus.OK\n        &lt;= response.status_code\n        &lt; HTTPStatus.MULTIPLE_CHOICES  # 2xx\n    ):\n        if expected_model and parsed_model is not None:\n            # Ensure what we are caching is indeed of the expected_model type\n            if isinstance(parsed_model, expected_model):\n                self._cache[cache_key] = (\n                    parsed_model  # Store the already parsed model\n                )\n                logger.debug(f\"Cached parsed model for key: {cache_key}\")\n            else:\n                logger.warning(\n                    f\"Attempted to cache for key {cache_key}, but parsed_model type \"\n                    f\"{type(parsed_model)} does not match expected_model {expected_model}. Not caching.\"\n                )\n        elif expected_model and parsed_model is None:\n            logger.debug(\n                f\"GET request for {cache_key} successful, but model parsing failed or no model to parse. Not caching.\"\n            )\n\n    # --- Standard Response Handling ---\n    if expected_model:\n        if parsed_model is not None and isinstance(parsed_model, expected_model):\n            return parsed_model  # Return the successfully parsed model\n        # Parsing failed inside _execute_single_request (parsed_model is None)\n        # or it's not of the expected type (should be rare if parsing succeeded).\n        logger.warning(\n            f\"Expected model {expected_model.__name__} but parsing failed, model was None, \"\n            f\"or type mismatch for {method} {path}. Returning raw response.\"\n        )\n        return response  # Fallback to raw response\n\n    return response  # Default: return raw response if no expected_model\n</code></pre>"},{"location":"config/","title":"Configuration","text":""},{"location":"config/#bibliofabric.config","title":"<code>bibliofabric.config</code>","text":""},{"location":"config/#bibliofabric.config.BaseApiSettings","title":"<code>BaseApiSettings</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Manages user-configurable settings for API clients built on bibliofabric, primarily loaded from environment variables or a .env file.</p> <p>This base class provides generic configuration options for HTTP client behavior, caching, rate limiting, and request hooks that can be inherited by specific API client implementations.</p> Source code in <code>src/bibliofabric/config.py</code> <pre><code>class BaseApiSettings(BaseSettings):\n    \"\"\"\n    Manages user-configurable settings for API clients built on bibliofabric,\n    primarily loaded from environment variables or a .env file.\n\n    This base class provides generic configuration options for HTTP client behavior,\n    caching, rate limiting, and request hooks that can be inherited by specific\n    API client implementations.\n    \"\"\"\n\n    model_config = SettingsConfigDict(\n        env_file=(\".env\", \"secrets.env\"),  # Look in both .env and secrets.env\n        env_file_encoding=\"utf-8\",\n        # Environment variables should be prefixed by the specific implementation\n        env_prefix=\"\",  # To be overridden by inheriting classes\n        extra=\"ignore\",  # Ignore extra fields found in environment\n        case_sensitive=False,  # Allow flexible casing in environment variables\n        arbitrary_types_allowed=True,  # Allow hook callables\n    )\n\n    # --- Client Behavior Settings ---\n    request_timeout: float = Field(\n        default=30.0, description=\"Default request timeout in seconds\"\n    )\n    max_retries: int = Field(\n        default=3, description=\"Maximum number of retries for failed requests\"\n    )\n    backoff_factor: float = Field(\n        default=0.5, description=\"Backoff factor for retries (seconds)\"\n    )\n    user_agent: str = Field(\n        default=\"bibliofabric/1.0.0\",\n        description=\"User-Agent header for requests\",\n    )\n\n    # --- Rate Limiting Settings ---\n    enable_rate_limiting: bool = Field(\n        default=True, description=\"Enable/disable API rate limiting features\"\n    )\n    rate_limit_buffer_percentage: float = Field(\n        default=0.1,\n        description=\"Buffer percentage to consider rate limit approaching (e.g., 0.1 for 10%)\",\n    )\n    rate_limit_retry_after_default: int = Field(\n        default=60,\n        description=\"Default wait time in seconds if Retry-After header is not present on 429\",\n    )\n\n    # --- Caching Settings ---\n    enable_caching: bool = Field(\n        default=False, description=\"Enable/disable client-side caching\"\n    )\n    cache_ttl_seconds: int = Field(\n        default=300,\n        description=\"Default TTL for cache entries in seconds (e.g., 300 for 5 minutes)\",\n    )\n    cache_max_size: int = Field(\n        default=128, description=\"Maximum number of items in the LRU cache\"\n    )\n\n    # --- Hook Settings ---\n    pre_request_hooks: list[PreRequestHook] = Field(\n        default_factory=list,\n        description=\"List of hooks to call before a request is made.\",\n    )\n    post_request_hooks: list[PostRequestHook] = Field(\n        default_factory=list,\n        description=\"List of hooks to call after a response is received and parsed.\",\n    )\n</code></pre>"},{"location":"config/#bibliofabric.config.get_base_settings","title":"<code>get_base_settings()</code>  <code>cached</code>","text":"<p>Provides access to the base API settings.</p> <p>Settings are loaded from environment variables or .env/secrets.env files. The instance is cached for performance.</p> <p>Note: This function provides only the base settings. Specific API client implementations should provide their own settings factory functions.</p> <p>Returns:</p> Name Type Description <code>BaseApiSettings</code> <code>BaseApiSettings</code> <p>The base API settings instance.</p> Source code in <code>src/bibliofabric/config.py</code> <pre><code>@lru_cache\ndef get_base_settings() -&gt; BaseApiSettings:\n    \"\"\"\n    Provides access to the base API settings.\n\n    Settings are loaded from environment variables or .env/secrets.env files.\n    The instance is cached for performance.\n\n    Note: This function provides only the base settings. Specific API client\n    implementations should provide their own settings factory functions.\n\n    Returns:\n        BaseApiSettings: The base API settings instance.\n    \"\"\"\n    return BaseApiSettings()\n</code></pre>"},{"location":"exceptions/","title":"Exceptions","text":""},{"location":"exceptions/#bibliofabric.exceptions","title":"<code>bibliofabric.exceptions</code>","text":"<p>Custom exception classes for the Bibliofabric library.</p>"},{"location":"exceptions/#bibliofabric.exceptions.APIError","title":"<code>APIError</code>","text":"<p>               Bases: <code>BibliofabricError</code></p> <p>Represents a generic error returned by an API (non-specific 4xx/5xx).</p> Source code in <code>src/bibliofabric/exceptions.py</code> <pre><code>class APIError(BibliofabricError):\n    \"\"\"Represents a generic error returned by an API (non-specific 4xx/5xx).\"\"\"\n</code></pre>"},{"location":"exceptions/#bibliofabric.exceptions.AuthError","title":"<code>AuthError</code>","text":"<p>               Bases: <code>BibliofabricError</code></p> <p>Raised when an authentication error occurs, e.g., fetching a token fails.</p> Source code in <code>src/bibliofabric/exceptions.py</code> <pre><code>class AuthError(BibliofabricError):\n    \"\"\"Raised when an authentication error occurs, e.g., fetching a token fails.\"\"\"\n</code></pre>"},{"location":"exceptions/#bibliofabric.exceptions.BibliofabricError","title":"<code>BibliofabricError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception class for all Bibliofabric errors.</p> Source code in <code>src/bibliofabric/exceptions.py</code> <pre><code>class BibliofabricError(Exception):\n    \"\"\"Base exception class for all Bibliofabric errors.\"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        *,\n        response: httpx.Response | None = None,\n        request: httpx.Request | None = None,\n    ):\n        \"\"\"Initializes the base exception.\n\n        Args:\n            message: The error message.\n            response: Optional httpx.Response object associated with the error.\n            request: Optional httpx.Request object associated with the error.\n        \"\"\"\n        super().__init__(message)\n        self.message = message\n        self.response = response\n        self.request = request\n\n    def __str__(self) -&gt; str:\n        if self.response:\n            # Prefer response info if available\n            url_info = getattr(getattr(self.response, \"request\", None), \"url\", \"N/A\")\n            return (\n                f\"{self.message} (Status: {self.response.status_code}, URL: {url_info})\"\n            )\n        # Check type before accessing attribute\n        if isinstance(self.request, httpx.Request):\n            # Fallback to request info if response is missing and request is valid\n            return f\"{self.message} (URL: {self.request.url})\"\n        # Default message if neither response nor valid request is available\n        return self.message\n</code></pre>"},{"location":"exceptions/#bibliofabric.exceptions.BibliofabricError.__init__","title":"<code>__init__(message, *, response=None, request=None)</code>","text":"<p>Initializes the base exception.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The error message.</p> required <code>response</code> <code>Response | None</code> <p>Optional httpx.Response object associated with the error.</p> <code>None</code> <code>request</code> <code>Request | None</code> <p>Optional httpx.Request object associated with the error.</p> <code>None</code> Source code in <code>src/bibliofabric/exceptions.py</code> <pre><code>def __init__(\n    self,\n    message: str,\n    *,\n    response: httpx.Response | None = None,\n    request: httpx.Request | None = None,\n):\n    \"\"\"Initializes the base exception.\n\n    Args:\n        message: The error message.\n        response: Optional httpx.Response object associated with the error.\n        request: Optional httpx.Request object associated with the error.\n    \"\"\"\n    super().__init__(message)\n    self.message = message\n    self.response = response\n    self.request = request\n</code></pre>"},{"location":"exceptions/#bibliofabric.exceptions.BibliofabricRequestError","title":"<code>BibliofabricRequestError</code>","text":"<p>               Bases: <code>BibliofabricError</code></p> <p>Represents an error during the HTTP request process itself.</p> <p>This can be due to network issues, timeouts, or HTTP errors from the server that are not covered by more specific exceptions like RateLimitError or NotFoundError.</p> Source code in <code>src/bibliofabric/exceptions.py</code> <pre><code>class BibliofabricRequestError(BibliofabricError):\n    \"\"\"Represents an error during the HTTP request process itself.\n\n    This can be due to network issues, timeouts, or HTTP errors from the server\n    that are not covered by more specific exceptions like RateLimitError or NotFoundError.\n    \"\"\"\n</code></pre>"},{"location":"exceptions/#bibliofabric.exceptions.ConfigurationError","title":"<code>ConfigurationError</code>","text":"<p>               Bases: <code>BibliofabricError</code></p> <p>Represents an error in the library's configuration.</p> Source code in <code>src/bibliofabric/exceptions.py</code> <pre><code>class ConfigurationError(BibliofabricError):\n    \"\"\"Represents an error in the library's configuration.\"\"\"\n\n    def __init__(self, message: str):\n        # Configuration errors typically don't have an HTTP response\n        super().__init__(message, response=None)\n</code></pre>"},{"location":"exceptions/#bibliofabric.exceptions.NetworkError","title":"<code>NetworkError</code>","text":"<p>               Bases: <code>BibliofabricError</code></p> <p>Represents a network connection error (e.g., DNS resolution failure, connection refused).</p> <p>This error indicates a problem in establishing or maintaining a network connection to the server during an HTTP request.</p> Source code in <code>src/bibliofabric/exceptions.py</code> <pre><code>class NetworkError(BibliofabricError):\n    \"\"\"Represents a network connection error (e.g., DNS resolution failure, connection refused).\n\n    This error indicates a problem in establishing or maintaining a network connection\n    to the server during an HTTP request.\n    \"\"\"\n\n    def __init__(self, message: str, *, request: httpx.Request | None = None):\n        \"\"\"Initializes the NetworkError.\n\n        Args:\n            message: The error message.\n            request: The httpx.Request object associated with the network error.\n        \"\"\"\n        super().__init__(message, request=request, response=None)\n\n    def __str__(self) -&gt; str:\n        if self.request:\n            return f\"{self.message} (URL: {self.request.url})\"\n        return self.message\n</code></pre>"},{"location":"exceptions/#bibliofabric.exceptions.NetworkError.__init__","title":"<code>__init__(message, *, request=None)</code>","text":"<p>Initializes the NetworkError.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The error message.</p> required <code>request</code> <code>Request | None</code> <p>The httpx.Request object associated with the network error.</p> <code>None</code> Source code in <code>src/bibliofabric/exceptions.py</code> <pre><code>def __init__(self, message: str, *, request: httpx.Request | None = None):\n    \"\"\"Initializes the NetworkError.\n\n    Args:\n        message: The error message.\n        request: The httpx.Request object associated with the network error.\n    \"\"\"\n    super().__init__(message, request=request, response=None)\n</code></pre>"},{"location":"exceptions/#bibliofabric.exceptions.NotFoundError","title":"<code>NotFoundError</code>","text":"<p>               Bases: <code>APIError</code></p> <p>Represents a resource not found error (404 Not Found).</p> Source code in <code>src/bibliofabric/exceptions.py</code> <pre><code>class NotFoundError(APIError):\n    \"\"\"Represents a resource not found error (404 Not Found).\"\"\"\n</code></pre>"},{"location":"exceptions/#bibliofabric.exceptions.RateLimitError","title":"<code>RateLimitError</code>","text":"<p>               Bases: <code>APIError</code></p> <p>Represents hitting the API rate limit (429 Too Many Requests).</p> Source code in <code>src/bibliofabric/exceptions.py</code> <pre><code>class RateLimitError(APIError):\n    \"\"\"Represents hitting the API rate limit (429 Too Many Requests).\"\"\"\n</code></pre>"},{"location":"exceptions/#bibliofabric.exceptions.TimeoutError","title":"<code>TimeoutError</code>","text":"<p>               Bases: <code>BibliofabricError</code></p> <p>Represents a request timeout error.</p> <p>This error is raised when an HTTP request does not complete within the configured timeout.</p> Source code in <code>src/bibliofabric/exceptions.py</code> <pre><code>class TimeoutError(BibliofabricError):\n    \"\"\"Represents a request timeout error.\n\n    This error is raised when an HTTP request does not complete within the configured timeout.\n    \"\"\"\n\n    def __init__(self, message: str, *, request: httpx.Request | None = None):\n        \"\"\"Initializes the TimeoutError.\n\n        Args:\n            message: The error message.\n            request: The httpx.Request object associated with the timeout.\n        \"\"\"\n        super().__init__(message, request=request, response=None)\n\n    def __str__(self) -&gt; str:\n        if self.request:\n            return f\"{self.message} (URL: {self.request.url})\"\n        return self.message\n</code></pre>"},{"location":"exceptions/#bibliofabric.exceptions.TimeoutError.__init__","title":"<code>__init__(message, *, request=None)</code>","text":"<p>Initializes the TimeoutError.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The error message.</p> required <code>request</code> <code>Request | None</code> <p>The httpx.Request object associated with the timeout.</p> <code>None</code> Source code in <code>src/bibliofabric/exceptions.py</code> <pre><code>def __init__(self, message: str, *, request: httpx.Request | None = None):\n    \"\"\"Initializes the TimeoutError.\n\n    Args:\n        message: The error message.\n        request: The httpx.Request object associated with the timeout.\n    \"\"\"\n    super().__init__(message, request=request, response=None)\n</code></pre>"},{"location":"exceptions/#bibliofabric.exceptions.ValidationError","title":"<code>ValidationError</code>","text":"<p>               Bases: <code>BibliofabricError</code></p> <p>Represents a request validation error (e.g., invalid parameters, 400 Bad Request).</p> <p>Can also be raised for client-side validation issues before sending request.</p> Source code in <code>src/bibliofabric/exceptions.py</code> <pre><code>class ValidationError(BibliofabricError):\n    \"\"\"Represents a request validation error (e.g., invalid parameters, 400 Bad Request).\n\n    Can also be raised for client-side validation issues before sending request.\n    \"\"\"\n</code></pre>"},{"location":"models/","title":"Models","text":""},{"location":"models/#bibliofabric.models","title":"<code>bibliofabric.models</code>","text":"<p>Core protocols and interfaces for the bibliofabric framework.</p> <p>This module defines the essential protocols that enable the generic framework to work with different API response structures through pluggable patterns. The ResponseUnwrapper protocol is the key abstraction that allows any API client implementation to define how their specific JSON response format should be parsed and processed.</p>"},{"location":"models/#bibliofabric.models.ResponseUnwrapper","title":"<code>ResponseUnwrapper</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for unwrapping API-specific response structures.</p> <p>This protocol defines the interface that concrete implementations must satisfy to enable the generic bibliofabric framework to work with any API's response format. Each method handles a specific aspect of response parsing that varies between different APIs.</p> <p>The protocol enables a clean separation between generic HTTP client logic and API-specific response handling, making it easy to support new APIs by implementing this interface without modifying the core framework.</p> Example <p>For an OpenAIRE API response like:</p> <pre><code>{\n    \"header\": {\n        \"total\": 1000,  # [total]\n        \"nextCursor\": \"abc123\"  # [nextCursor]\n    },\n    \"results\": [\n        {\"id\": \"1\", \"title\": \"Paper 1\"},\n        {\"id\": \"2\", \"title\": \"Paper 2\"}\n    ]\n}\n</code></pre> Source code in <code>src/bibliofabric/models.py</code> <pre><code>@runtime_checkable\nclass ResponseUnwrapper(Protocol):\n    \"\"\"Protocol for unwrapping API-specific response structures.\n\n    This protocol defines the interface that concrete implementations must\n    satisfy to enable the generic bibliofabric framework to work with any\n    API's response format. Each method handles a specific aspect of response\n    parsing that varies between different APIs.\n\n    The protocol enables a clean separation between generic HTTP client logic\n    and API-specific response handling, making it easy to support new APIs\n    by implementing this interface without modifying the core framework.\n\n    Example:\n        For an OpenAIRE API response like:\n        ```json\n        {\n            \"header\": {\n                \"total\": 1000,  # [total]\n                \"nextCursor\": \"abc123\"  # [nextCursor]\n            },\n            \"results\": [\n                {\"id\": \"1\", \"title\": \"Paper 1\"},\n                {\"id\": \"2\", \"title\": \"Paper 2\"}\n            ]\n        }\n        ```\n\n        [total]: #total\n        [nextCursor]: #nextcursor\n    \"\"\"\n\n    def unwrap_results(self, response_json: dict[str, Any]) -&gt; list[dict[str, Any]]:\n        \"\"\"Extract the list of result items from an API response.\n\n        This method should parse the API response and return the list of\n        individual result items, regardless of how they are nested within\n        the response structure.\n\n        Args:\n            response_json: The complete JSON response from the API as a dictionary.\n\n        Returns:\n            list[dict[str, Any]]: A list of dictionaries, where each dictionary\n                represents a single result item from the API response.\n\n        Raises:\n            KeyError: If required response structure is missing.\n            ValueError: If response format is invalid or unexpected.\n\n        Example:\n            For OpenAIRE: return response_json.get(\"results\", [])\n            For Crossref: return response_json.get(\"message\", {}).get(\"items\", [])\n        \"\"\"\n        ...\n\n    def unwrap_single_item(self, response_json: dict[str, Any]) -&gt; dict[str, Any]:\n        \"\"\"Extract a single item from an API response.\n\n        This method should parse the API response when it contains a single\n        entity (e.g., from a GET /entities/{id} endpoint) and return that\n        entity's data.\n\n        Args:\n            response_json: The complete JSON response from the API as a dictionary.\n\n        Returns:\n            dict[str, Any]: A dictionary containing the single result item's data.\n\n        Raises:\n            KeyError: If required response structure is missing.\n            ValueError: If response format is invalid or contains no item.\n\n        Example:\n            For OpenAIRE: return response_json.get(\"results\", [{}])[0]\n            For Crossref: return response_json.get(\"message\", {})\n        \"\"\"\n        ...\n\n    def get_next_page_token(self, response_json: dict[str, Any]) -&gt; str | None:\n        \"\"\"Extract the pagination token for the next page from an API response.\n\n        This method should parse the API response and return the token, cursor,\n        or other identifier needed to fetch the next page of results. Returns\n        None if there are no more pages available.\n\n        Args:\n            response_json: The complete JSON response from the API as a dictionary.\n\n        Returns:\n            str | None: The pagination token/cursor for the next page, or None\n                if no more pages are available.\n\n        Note:\n            Different APIs use different pagination schemes:\n            - Cursor-based: return a cursor string\n            - Offset-based: return the next offset as a string\n            - Page-based: return the next page number as a string\n            - Link-based: extract the next URL and return relevant parts\n\n        Example:\n            For OpenAIRE: return response_json.get(\"header\", {}).get(\"nextCursor\")\n            For Crossref: return str(current_offset + page_size) if has_more else None\n        \"\"\"\n        ...\n\n    def get_total_results(self, response_json: dict[str, Any]) -&gt; int | None:\n        \"\"\"Extract the total count of results from an API response.\n\n        This method should parse the API response and return the total number\n        of results available across all pages, if this information is provided\n        by the API. Returns None if the total count is not available.\n\n        Args:\n            response_json: The complete JSON response from the API as a dictionary.\n\n        Returns:\n            int | None: The total number of results across all pages, or None\n                if this information is not available in the response.\n\n        Note:\n            Not all APIs provide total counts in their responses. Some only\n            indicate whether more results are available without giving the\n            exact total. In such cases, this method should return None.\n\n        Example:\n            For OpenAIRE: return response_json.get(\"header\", {}).get(\"total\")\n            For Crossref: return response_json.get(\"message\", {}).get(\"total-results\")\n        \"\"\"\n        ...\n</code></pre>"},{"location":"models/#bibliofabric.models.ResponseUnwrapper.get_next_page_token","title":"<code>get_next_page_token(response_json)</code>","text":"<p>Extract the pagination token for the next page from an API response.</p> <p>This method should parse the API response and return the token, cursor, or other identifier needed to fetch the next page of results. Returns None if there are no more pages available.</p> <p>Parameters:</p> Name Type Description Default <code>response_json</code> <code>dict[str, Any]</code> <p>The complete JSON response from the API as a dictionary.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>str | None: The pagination token/cursor for the next page, or None if no more pages are available.</p> Note <p>Different APIs use different pagination schemes: - Cursor-based: return a cursor string - Offset-based: return the next offset as a string - Page-based: return the next page number as a string - Link-based: extract the next URL and return relevant parts</p> Example <p>For OpenAIRE: return response_json.get(\"header\", {}).get(\"nextCursor\") For Crossref: return str(current_offset + page_size) if has_more else None</p> Source code in <code>src/bibliofabric/models.py</code> <pre><code>def get_next_page_token(self, response_json: dict[str, Any]) -&gt; str | None:\n    \"\"\"Extract the pagination token for the next page from an API response.\n\n    This method should parse the API response and return the token, cursor,\n    or other identifier needed to fetch the next page of results. Returns\n    None if there are no more pages available.\n\n    Args:\n        response_json: The complete JSON response from the API as a dictionary.\n\n    Returns:\n        str | None: The pagination token/cursor for the next page, or None\n            if no more pages are available.\n\n    Note:\n        Different APIs use different pagination schemes:\n        - Cursor-based: return a cursor string\n        - Offset-based: return the next offset as a string\n        - Page-based: return the next page number as a string\n        - Link-based: extract the next URL and return relevant parts\n\n    Example:\n        For OpenAIRE: return response_json.get(\"header\", {}).get(\"nextCursor\")\n        For Crossref: return str(current_offset + page_size) if has_more else None\n    \"\"\"\n    ...\n</code></pre>"},{"location":"models/#bibliofabric.models.ResponseUnwrapper.get_total_results","title":"<code>get_total_results(response_json)</code>","text":"<p>Extract the total count of results from an API response.</p> <p>This method should parse the API response and return the total number of results available across all pages, if this information is provided by the API. Returns None if the total count is not available.</p> <p>Parameters:</p> Name Type Description Default <code>response_json</code> <code>dict[str, Any]</code> <p>The complete JSON response from the API as a dictionary.</p> required <p>Returns:</p> Type Description <code>int | None</code> <p>int | None: The total number of results across all pages, or None if this information is not available in the response.</p> Note <p>Not all APIs provide total counts in their responses. Some only indicate whether more results are available without giving the exact total. In such cases, this method should return None.</p> Example <p>For OpenAIRE: return response_json.get(\"header\", {}).get(\"total\") For Crossref: return response_json.get(\"message\", {}).get(\"total-results\")</p> Source code in <code>src/bibliofabric/models.py</code> <pre><code>def get_total_results(self, response_json: dict[str, Any]) -&gt; int | None:\n    \"\"\"Extract the total count of results from an API response.\n\n    This method should parse the API response and return the total number\n    of results available across all pages, if this information is provided\n    by the API. Returns None if the total count is not available.\n\n    Args:\n        response_json: The complete JSON response from the API as a dictionary.\n\n    Returns:\n        int | None: The total number of results across all pages, or None\n            if this information is not available in the response.\n\n    Note:\n        Not all APIs provide total counts in their responses. Some only\n        indicate whether more results are available without giving the\n        exact total. In such cases, this method should return None.\n\n    Example:\n        For OpenAIRE: return response_json.get(\"header\", {}).get(\"total\")\n        For Crossref: return response_json.get(\"message\", {}).get(\"total-results\")\n    \"\"\"\n    ...\n</code></pre>"},{"location":"models/#bibliofabric.models.ResponseUnwrapper.unwrap_results","title":"<code>unwrap_results(response_json)</code>","text":"<p>Extract the list of result items from an API response.</p> <p>This method should parse the API response and return the list of individual result items, regardless of how they are nested within the response structure.</p> <p>Parameters:</p> Name Type Description Default <code>response_json</code> <code>dict[str, Any]</code> <p>The complete JSON response from the API as a dictionary.</p> required <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>list[dict[str, Any]]: A list of dictionaries, where each dictionary represents a single result item from the API response.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If required response structure is missing.</p> <code>ValueError</code> <p>If response format is invalid or unexpected.</p> Example <p>For OpenAIRE: return response_json.get(\"results\", []) For Crossref: return response_json.get(\"message\", {}).get(\"items\", [])</p> Source code in <code>src/bibliofabric/models.py</code> <pre><code>def unwrap_results(self, response_json: dict[str, Any]) -&gt; list[dict[str, Any]]:\n    \"\"\"Extract the list of result items from an API response.\n\n    This method should parse the API response and return the list of\n    individual result items, regardless of how they are nested within\n    the response structure.\n\n    Args:\n        response_json: The complete JSON response from the API as a dictionary.\n\n    Returns:\n        list[dict[str, Any]]: A list of dictionaries, where each dictionary\n            represents a single result item from the API response.\n\n    Raises:\n        KeyError: If required response structure is missing.\n        ValueError: If response format is invalid or unexpected.\n\n    Example:\n        For OpenAIRE: return response_json.get(\"results\", [])\n        For Crossref: return response_json.get(\"message\", {}).get(\"items\", [])\n    \"\"\"\n    ...\n</code></pre>"},{"location":"models/#bibliofabric.models.ResponseUnwrapper.unwrap_single_item","title":"<code>unwrap_single_item(response_json)</code>","text":"<p>Extract a single item from an API response.</p> <p>This method should parse the API response when it contains a single entity (e.g., from a GET /entities/{id} endpoint) and return that entity's data.</p> <p>Parameters:</p> Name Type Description Default <code>response_json</code> <code>dict[str, Any]</code> <p>The complete JSON response from the API as a dictionary.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing the single result item's data.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If required response structure is missing.</p> <code>ValueError</code> <p>If response format is invalid or contains no item.</p> Example <p>For OpenAIRE: return response_json.get(\"results\", [{}])[0] For Crossref: return response_json.get(\"message\", {})</p> Source code in <code>src/bibliofabric/models.py</code> <pre><code>def unwrap_single_item(self, response_json: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"Extract a single item from an API response.\n\n    This method should parse the API response when it contains a single\n    entity (e.g., from a GET /entities/{id} endpoint) and return that\n    entity's data.\n\n    Args:\n        response_json: The complete JSON response from the API as a dictionary.\n\n    Returns:\n        dict[str, Any]: A dictionary containing the single result item's data.\n\n    Raises:\n        KeyError: If required response structure is missing.\n        ValueError: If response format is invalid or contains no item.\n\n    Example:\n        For OpenAIRE: return response_json.get(\"results\", [{}])[0]\n        For Crossref: return response_json.get(\"message\", {})\n    \"\"\"\n    ...\n</code></pre>"},{"location":"resources/","title":"Resources","text":""},{"location":"resources/#bibliofabric.resources","title":"<code>bibliofabric.resources</code>","text":"<p>Generic resource mixins for the bibliofabric framework.</p> <p>This module provides reusable base classes and mixins that abstract common API resource operations like getting single entities, searching with pagination, and cursor-based iteration. These mixins work with the BaseApiClient and ResponseUnwrapper protocol to provide a consistent interface across different API implementations.</p> <p>The mixins are designed to be composable - a concrete resource client can inherit from multiple mixins as needed to provide the appropriate functionality for that specific resource type.</p>"},{"location":"resources/#bibliofabric.resources.BaseResourceClient","title":"<code>BaseResourceClient</code>","text":"<p>Base class for all resource clients in the bibliofabric framework.</p> <p>This class provides the foundation for resource clients by holding a reference to the main API client and providing access to the response unwrapper. All resource mixins expect to be used with this base class.</p> <p>Attributes:</p> Name Type Description <code>_api_client</code> <p>The main <code>BaseApiClient</code> instance used for making HTTP requests.</p> <code>_entity_path</code> <p>The specific API endpoint path for this resource (e.g., \"items\", \"users\"). This must be defined by concrete subclasses.</p> <code>_entity_model</code> <p>Optional Pydantic model (<code>type[BaseModel] | None</code>) that represents a single entity of this resource. If provided, methods like <code>get()</code> and <code>iterate()</code> will attempt to parse results into this model.</p> <code>_search_response_model</code> <p>Optional Pydantic model (<code>type[BaseModel] | None</code>) that represents the structure of a search or list response envelope for this resource. If provided, <code>search()</code> will attempt to parse the entire response into this model.</p> Source code in <code>src/bibliofabric/resources.py</code> <pre><code>class BaseResourceClient:\n    \"\"\"Base class for all resource clients in the bibliofabric framework.\n\n    This class provides the foundation for resource clients by holding a\n    reference to the main API client and providing access to the response\n    unwrapper. All resource mixins expect to be used with this base class.\n\n    Attributes:\n        _api_client: The main `BaseApiClient` instance used for making HTTP requests.\n        _entity_path: The specific API endpoint path for this resource (e.g., \"items\",\n            \"users\"). This must be defined by concrete subclasses.\n        _entity_model: Optional Pydantic model (`type[BaseModel] | None`) that represents\n            a single entity of this resource. If provided, methods like `get()`\n            and `iterate()` will attempt to parse results into this model.\n        _search_response_model: Optional Pydantic model (`type[BaseModel] | None`)\n            that represents the structure of a search or list response envelope for\n            this resource. If provided, `search()` will attempt to parse the entire\n            response into this model.\n    \"\"\"\n\n    def __init__(self, api_client: \"BaseApiClient\"):\n        \"\"\"Initialize the base resource client.\n\n        Args:\n            api_client: An instance of BaseApiClient for making HTTP requests.\n        \"\"\"\n        self._api_client = api_client\n        logger.debug(f\"{self.__class__.__name__} initialized\")\n\n    @property\n    def response_unwrapper(self) -&gt; \"ResponseUnwrapper\":\n        \"\"\"Get the response unwrapper from the API client.\n\n        Returns:\n            ResponseUnwrapper: The response unwrapper instance from the API client.\n        \"\"\"\n        return self._api_client._response_unwrapper\n</code></pre>"},{"location":"resources/#bibliofabric.resources.BaseResourceClient.response_unwrapper","title":"<code>response_unwrapper</code>  <code>property</code>","text":"<p>Get the response unwrapper from the API client.</p> <p>Returns:</p> Name Type Description <code>ResponseUnwrapper</code> <code>ResponseUnwrapper</code> <p>The response unwrapper instance from the API client.</p>"},{"location":"resources/#bibliofabric.resources.BaseResourceClient.__init__","title":"<code>__init__(api_client)</code>","text":"<p>Initialize the base resource client.</p> <p>Parameters:</p> Name Type Description Default <code>api_client</code> <code>BaseApiClient</code> <p>An instance of BaseApiClient for making HTTP requests.</p> required Source code in <code>src/bibliofabric/resources.py</code> <pre><code>def __init__(self, api_client: \"BaseApiClient\"):\n    \"\"\"Initialize the base resource client.\n\n    Args:\n        api_client: An instance of BaseApiClient for making HTTP requests.\n    \"\"\"\n    self._api_client = api_client\n    logger.debug(f\"{self.__class__.__name__} initialized\")\n</code></pre>"},{"location":"resources/#bibliofabric.resources.CursorIterableMixin","title":"<code>CursorIterableMixin</code>","text":"<p>Mixin that provides generic iterate() functionality using cursor-based pagination.</p> <p>This mixin implements a standard pattern for iterating through all results of a resource using cursor-based pagination. It automatically handles fetching subsequent pages by using the <code>nextCursor</code> (or equivalent) provided by the API, as interpreted by the <code>ResponseUnwrapper</code>. It yields individual entities.</p> <p>To use this mixin, a class must: 1. Inherit from <code>BaseResourceClient</code> (or a class that provides the    <code>ResourceClientProtocol</code> attributes, including access to a <code>ResponseUnwrapper</code>). 2. Define <code>_entity_path: str</code> specifying the API endpoint path for the resource. 3. Optionally, define <code>_entity_model: type[BaseModel] | None</code>. If provided,    each yielded entity will be parsed into an instance of this model.    If None, raw dictionary data for each entity is yielded.</p> Source code in <code>src/bibliofabric/resources.py</code> <pre><code>class CursorIterableMixin:\n    \"\"\"Mixin that provides generic iterate() functionality using cursor-based pagination.\n\n    This mixin implements a standard pattern for iterating through all results\n    of a resource using cursor-based pagination. It automatically handles fetching\n    subsequent pages by using the `nextCursor` (or equivalent) provided by the API,\n    as interpreted by the `ResponseUnwrapper`. It yields individual entities.\n\n    To use this mixin, a class must:\n    1. Inherit from `BaseResourceClient` (or a class that provides the\n       `ResourceClientProtocol` attributes, including access to a `ResponseUnwrapper`).\n    2. Define `_entity_path: str` specifying the API endpoint path for the resource.\n    3. Optionally, define `_entity_model: type[BaseModel] | None`. If provided,\n       each yielded entity will be parsed into an instance of this model.\n       If None, raw dictionary data for each entity is yielded.\n    \"\"\"\n\n    async def iterate(\n        self: ResourceClientProtocol,\n        page_size: int = 100,\n        sort_by: str | None = None,\n        filters: BaseModel | dict[str, Any] | None = None,\n    ) -&gt; AsyncIterator[Any]:\n        \"\"\"Iterate through all entities matching the criteria using cursor pagination.\n\n        This method automatically handles pagination by using cursors to fetch\n        successive pages of results. It yields individual entities as they are\n        retrieved from each page.\n\n        Args:\n            page_size: Number of results to fetch per API call during iteration.\n            sort_by: Field to sort by.\n            filters: Filter criteria as a Pydantic model or dictionary.\n\n        Yields:\n            Any: Individual entities, either as parsed Pydantic models (if\n                _entity_model is defined) or as raw dictionaries.\n\n        Raises:\n            BibliofabricError: If the API request fails during iteration.\n        \"\"\"\n        if not self._entity_path:\n            raise BibliofabricError(\n                f\"{self.__class__.__name__} must define _entity_path\"\n            )\n\n        # Convert filters to dictionary if it's a Pydantic model\n        filter_dict: dict[str, Any] = {}\n        if filters:\n            if isinstance(filters, BaseModel):\n                filter_dict = filters.model_dump(exclude_none=True, by_alias=True)\n            elif isinstance(filters, dict):\n                filter_dict = filters\n            else:\n                raise BibliofabricError(\n                    f\"filters must be a Pydantic model or dictionary, got {type(filters)}\"\n                )\n\n        logger.info(\n            f\"Iterating {self._entity_path}: pageSize={page_size}, \"\n            f\"sort='{sort_by}', filters={filter_dict}\"\n        )\n\n        # Build initial parameters with cursor pagination\n        current_params: dict[\n            str, Any\n        ] = {  # Renamed to current_params for clarity in loop\n            \"cursor\": \"*\",  # Start cursor for iteration\n            \"pageSize\": page_size,\n        }\n\n        if sort_by:\n            current_params[\"sortBy\"] = sort_by\n\n        if filter_dict:\n            current_params.update(filter_dict)\n\n        while True:\n            try:\n                logger.debug(\n                    f\"Iterating {self._entity_path} with params: {current_params}\"\n                )\n\n                # Pass a copy of params to avoid issues with mock call_args_list\n                response = await self._api_client.request(\n                    \"GET\", self._entity_path, params=current_params.copy()\n                )\n\n                response_data = response.json()\n\n                # Use the response unwrapper to get results and next cursor\n                results = self.response_unwrapper.unwrap_results(response_data)\n                next_cursor = self.response_unwrapper.get_next_page_token(response_data)\n\n                if not results:\n                    logger.debug(\n                        f\"No more results for {self._entity_path}, stopping iteration.\"\n                    )\n                    break\n\n                # Yield each result\n                for result_data in results:\n                    # Parse with entity model if available\n                    if self._entity_model:\n                        try:\n                            yield self._entity_model.model_validate(result_data)\n                        except Exception as e:\n                            logger.warning(\n                                f\"Failed to parse entity data with {self._entity_model.__name__}: {e}. \"\n                                \"Yielding raw data.\"\n                            )\n                            yield result_data\n                    else:\n                        yield result_data\n\n                # Check if there are more pages\n                if not next_cursor:\n                    logger.debug(\n                        f\"No nextCursor for {self._entity_path}, stopping iteration.\"\n                    )\n                    break\n\n                # Update cursor for next iteration\n                current_params[\"cursor\"] = next_cursor\n                # Remove page if it accidentally got in, cursor handles pagination\n                current_params.pop(\"page\", None)\n\n            except Exception as e:\n                if isinstance(e, BibliofabricError):\n                    raise\n                logger.exception(\n                    f\"Failed during iteration of {self._entity_path} with params {current_params}\"\n                )\n                raise BibliofabricError(\n                    f\"Unexpected error during iteration of {self._entity_path}: {e}\"\n                ) from e\n</code></pre>"},{"location":"resources/#bibliofabric.resources.CursorIterableMixin.iterate","title":"<code>iterate(page_size=100, sort_by=None, filters=None)</code>  <code>async</code>","text":"<p>Iterate through all entities matching the criteria using cursor pagination.</p> <p>This method automatically handles pagination by using cursors to fetch successive pages of results. It yields individual entities as they are retrieved from each page.</p> <p>Parameters:</p> Name Type Description Default <code>page_size</code> <code>int</code> <p>Number of results to fetch per API call during iteration.</p> <code>100</code> <code>sort_by</code> <code>str | None</code> <p>Field to sort by.</p> <code>None</code> <code>filters</code> <code>BaseModel | dict[str, Any] | None</code> <p>Filter criteria as a Pydantic model or dictionary.</p> <code>None</code> <p>Yields:</p> Name Type Description <code>Any</code> <code>AsyncIterator[Any]</code> <p>Individual entities, either as parsed Pydantic models (if _entity_model is defined) or as raw dictionaries.</p> <p>Raises:</p> Type Description <code>BibliofabricError</code> <p>If the API request fails during iteration.</p> Source code in <code>src/bibliofabric/resources.py</code> <pre><code>async def iterate(\n    self: ResourceClientProtocol,\n    page_size: int = 100,\n    sort_by: str | None = None,\n    filters: BaseModel | dict[str, Any] | None = None,\n) -&gt; AsyncIterator[Any]:\n    \"\"\"Iterate through all entities matching the criteria using cursor pagination.\n\n    This method automatically handles pagination by using cursors to fetch\n    successive pages of results. It yields individual entities as they are\n    retrieved from each page.\n\n    Args:\n        page_size: Number of results to fetch per API call during iteration.\n        sort_by: Field to sort by.\n        filters: Filter criteria as a Pydantic model or dictionary.\n\n    Yields:\n        Any: Individual entities, either as parsed Pydantic models (if\n            _entity_model is defined) or as raw dictionaries.\n\n    Raises:\n        BibliofabricError: If the API request fails during iteration.\n    \"\"\"\n    if not self._entity_path:\n        raise BibliofabricError(\n            f\"{self.__class__.__name__} must define _entity_path\"\n        )\n\n    # Convert filters to dictionary if it's a Pydantic model\n    filter_dict: dict[str, Any] = {}\n    if filters:\n        if isinstance(filters, BaseModel):\n            filter_dict = filters.model_dump(exclude_none=True, by_alias=True)\n        elif isinstance(filters, dict):\n            filter_dict = filters\n        else:\n            raise BibliofabricError(\n                f\"filters must be a Pydantic model or dictionary, got {type(filters)}\"\n            )\n\n    logger.info(\n        f\"Iterating {self._entity_path}: pageSize={page_size}, \"\n        f\"sort='{sort_by}', filters={filter_dict}\"\n    )\n\n    # Build initial parameters with cursor pagination\n    current_params: dict[\n        str, Any\n    ] = {  # Renamed to current_params for clarity in loop\n        \"cursor\": \"*\",  # Start cursor for iteration\n        \"pageSize\": page_size,\n    }\n\n    if sort_by:\n        current_params[\"sortBy\"] = sort_by\n\n    if filter_dict:\n        current_params.update(filter_dict)\n\n    while True:\n        try:\n            logger.debug(\n                f\"Iterating {self._entity_path} with params: {current_params}\"\n            )\n\n            # Pass a copy of params to avoid issues with mock call_args_list\n            response = await self._api_client.request(\n                \"GET\", self._entity_path, params=current_params.copy()\n            )\n\n            response_data = response.json()\n\n            # Use the response unwrapper to get results and next cursor\n            results = self.response_unwrapper.unwrap_results(response_data)\n            next_cursor = self.response_unwrapper.get_next_page_token(response_data)\n\n            if not results:\n                logger.debug(\n                    f\"No more results for {self._entity_path}, stopping iteration.\"\n                )\n                break\n\n            # Yield each result\n            for result_data in results:\n                # Parse with entity model if available\n                if self._entity_model:\n                    try:\n                        yield self._entity_model.model_validate(result_data)\n                    except Exception as e:\n                        logger.warning(\n                            f\"Failed to parse entity data with {self._entity_model.__name__}: {e}. \"\n                            \"Yielding raw data.\"\n                        )\n                        yield result_data\n                else:\n                    yield result_data\n\n            # Check if there are more pages\n            if not next_cursor:\n                logger.debug(\n                    f\"No nextCursor for {self._entity_path}, stopping iteration.\"\n                )\n                break\n\n            # Update cursor for next iteration\n            current_params[\"cursor\"] = next_cursor\n            # Remove page if it accidentally got in, cursor handles pagination\n            current_params.pop(\"page\", None)\n\n        except Exception as e:\n            if isinstance(e, BibliofabricError):\n                raise\n            logger.exception(\n                f\"Failed during iteration of {self._entity_path} with params {current_params}\"\n            )\n            raise BibliofabricError(\n                f\"Unexpected error during iteration of {self._entity_path}: {e}\"\n            ) from e\n</code></pre>"},{"location":"resources/#bibliofabric.resources.GettableMixin","title":"<code>GettableMixin</code>","text":"<p>Mixin that provides generic get() functionality for retrieving single entities.</p> <p>This mixin implements a standard pattern for fetching individual entities by ID. It typically uses a search operation filtered by the entity's ID, as some APIs may not offer direct GET-by-ID endpoints, or this approach offers more consistency.</p> <p>To use this mixin, a class must: 1. Inherit from <code>BaseResourceClient</code> (or a class that provides the    <code>ResourceClientProtocol</code> attributes). 2. Define <code>_entity_path: str</code> specifying the API endpoint path for the resource. 3. Optionally, define <code>_entity_model: type[BaseModel] | None</code>. If provided,    the retrieved entity data will be parsed into an instance of this model.    If None, raw dictionary data is returned.</p> Source code in <code>src/bibliofabric/resources.py</code> <pre><code>class GettableMixin:\n    \"\"\"Mixin that provides generic get() functionality for retrieving single entities.\n\n    This mixin implements a standard pattern for fetching individual entities by ID.\n    It typically uses a search operation filtered by the entity's ID, as some APIs\n    may not offer direct GET-by-ID endpoints, or this approach offers more\n    consistency.\n\n    To use this mixin, a class must:\n    1. Inherit from `BaseResourceClient` (or a class that provides the\n       `ResourceClientProtocol` attributes).\n    2. Define `_entity_path: str` specifying the API endpoint path for the resource.\n    3. Optionally, define `_entity_model: type[BaseModel] | None`. If provided,\n       the retrieved entity data will be parsed into an instance of this model.\n       If None, raw dictionary data is returned.\n    \"\"\"\n\n    async def get(self: ResourceClientProtocol, entity_id: str) -&gt; Any:\n        \"\"\"Retrieve a single entity by its ID.\n\n        This method performs a search operation with the entity ID to fetch\n        a single entity. It uses the response unwrapper to extract the entity\n        data from the API response.\n\n        Args:\n            entity_id: The unique identifier of the entity to retrieve.\n\n        Returns:\n            Any: The entity data, either as a parsed Pydantic model (if _entity_model\n                is defined) or as a raw dictionary.\n\n        Raises:\n            BibliofabricError: If the entity is not found or if the API request fails.\n        \"\"\"\n        if not self._entity_path:\n            raise BibliofabricError(\n                f\"{self.__class__.__name__} must define _entity_path\"\n            )\n\n        logger.info(f\"Fetching entity with ID: {entity_id}\")\n\n        try:\n            # Use search with ID parameter instead of direct GET\n            params = {\"id\": entity_id, \"pageSize\": 1}\n\n            response = await self._api_client.request(\n                \"GET\", self._entity_path, params=params\n            )\n\n            response_data = response.json()\n\n            # Use the response unwrapper to get results\n            results = self.response_unwrapper.unwrap_results(response_data)\n\n            if not results:\n                entity_name = (\n                    self._entity_model.__name__ if self._entity_model else \"Entity\"\n                )\n                raise BibliofabricError(\n                    f\"{entity_name} with ID '{entity_id}' not found.\"\n                )\n\n            # Get the first (and should be only) result\n            entity_data = results[0]\n\n            # Parse with entity model if available\n            if self._entity_model:\n                try:\n                    return self._entity_model.model_validate(entity_data)\n                except Exception as e:\n                    logger.warning(\n                        f\"Failed to parse entity data with {self._entity_model.__name__}: {e}. \"\n                        \"Returning raw data.\"\n                    )\n                    return entity_data\n\n            return entity_data\n\n        except Exception as e:\n            if isinstance(e, BibliofabricError):\n                raise\n            logger.exception(\n                f\"Failed to fetch entity {entity_id} from {self._entity_path}\"\n            )\n            raise BibliofabricError(\n                f\"Unexpected error fetching entity {entity_id}: {e}\"\n            ) from e\n</code></pre>"},{"location":"resources/#bibliofabric.resources.GettableMixin.get","title":"<code>get(entity_id)</code>  <code>async</code>","text":"<p>Retrieve a single entity by its ID.</p> <p>This method performs a search operation with the entity ID to fetch a single entity. It uses the response unwrapper to extract the entity data from the API response.</p> <p>Parameters:</p> Name Type Description Default <code>entity_id</code> <code>str</code> <p>The unique identifier of the entity to retrieve.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The entity data, either as a parsed Pydantic model (if _entity_model is defined) or as a raw dictionary.</p> <p>Raises:</p> Type Description <code>BibliofabricError</code> <p>If the entity is not found or if the API request fails.</p> Source code in <code>src/bibliofabric/resources.py</code> <pre><code>async def get(self: ResourceClientProtocol, entity_id: str) -&gt; Any:\n    \"\"\"Retrieve a single entity by its ID.\n\n    This method performs a search operation with the entity ID to fetch\n    a single entity. It uses the response unwrapper to extract the entity\n    data from the API response.\n\n    Args:\n        entity_id: The unique identifier of the entity to retrieve.\n\n    Returns:\n        Any: The entity data, either as a parsed Pydantic model (if _entity_model\n            is defined) or as a raw dictionary.\n\n    Raises:\n        BibliofabricError: If the entity is not found or if the API request fails.\n    \"\"\"\n    if not self._entity_path:\n        raise BibliofabricError(\n            f\"{self.__class__.__name__} must define _entity_path\"\n        )\n\n    logger.info(f\"Fetching entity with ID: {entity_id}\")\n\n    try:\n        # Use search with ID parameter instead of direct GET\n        params = {\"id\": entity_id, \"pageSize\": 1}\n\n        response = await self._api_client.request(\n            \"GET\", self._entity_path, params=params\n        )\n\n        response_data = response.json()\n\n        # Use the response unwrapper to get results\n        results = self.response_unwrapper.unwrap_results(response_data)\n\n        if not results:\n            entity_name = (\n                self._entity_model.__name__ if self._entity_model else \"Entity\"\n            )\n            raise BibliofabricError(\n                f\"{entity_name} with ID '{entity_id}' not found.\"\n            )\n\n        # Get the first (and should be only) result\n        entity_data = results[0]\n\n        # Parse with entity model if available\n        if self._entity_model:\n            try:\n                return self._entity_model.model_validate(entity_data)\n            except Exception as e:\n                logger.warning(\n                    f\"Failed to parse entity data with {self._entity_model.__name__}: {e}. \"\n                    \"Returning raw data.\"\n                )\n                return entity_data\n\n        return entity_data\n\n    except Exception as e:\n        if isinstance(e, BibliofabricError):\n            raise\n        logger.exception(\n            f\"Failed to fetch entity {entity_id} from {self._entity_path}\"\n        )\n        raise BibliofabricError(\n            f\"Unexpected error fetching entity {entity_id}: {e}\"\n        ) from e\n</code></pre>"},{"location":"resources/#bibliofabric.resources.ResourceClientProtocol","title":"<code>ResourceClientProtocol</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol that defines the interface expected by resource mixins.</p> <p>This protocol ensures that classes using the mixins have the required attributes and methods that the mixins depend on.</p> Source code in <code>src/bibliofabric/resources.py</code> <pre><code>class ResourceClientProtocol(Protocol):\n    \"\"\"Protocol that defines the interface expected by resource mixins.\n\n    This protocol ensures that classes using the mixins have the required\n    attributes and methods that the mixins depend on.\n    \"\"\"\n\n    _api_client: \"BaseApiClient\"\n    _entity_path: str  # The relative API path for the resource, e.g., \"publications\"\n    _entity_model: type[BaseModel] | None  # Pydantic model for a single entity\n    _search_response_model: (\n        type[BaseModel] | None\n    )  # Pydantic model for the search/list response envelope\n\n    @property\n    def response_unwrapper(self) -&gt; \"ResponseUnwrapper\": ...\n</code></pre>"},{"location":"resources/#bibliofabric.resources.SearchableMixin","title":"<code>SearchableMixin</code>","text":"<p>Mixin that provides generic search() functionality with pagination support.</p> <p>This mixin implements a standard pattern for searching entities with support for page-based pagination, filtering, and sorting. It relies on the <code>ResponseUnwrapper</code> (via <code>BaseResourceClient</code>) to correctly parse the API's specific list response structure.</p> <p>To use this mixin, a class must: 1. Inherit from <code>BaseResourceClient</code> (or a class that provides the    <code>ResourceClientProtocol</code> attributes). 2. Define <code>_entity_path: str</code> specifying the API endpoint path for the resource. 3. Optionally, define <code>_search_response_model: type[BaseModel] | None</code>.    If provided, the entire search response (including pagination details and    results) will be parsed into an instance of this model. If None, the raw    JSON response dictionary is returned. 4. Optionally, define <code>_valid_sort_fields: frozenset[str]</code> if you want to    validate the <code>sort_by</code> parameter against a predefined set of fields.</p> Source code in <code>src/bibliofabric/resources.py</code> <pre><code>class SearchableMixin:\n    \"\"\"Mixin that provides generic search() functionality with pagination support.\n\n    This mixin implements a standard pattern for searching entities with support\n    for page-based pagination, filtering, and sorting. It relies on the\n    `ResponseUnwrapper` (via `BaseResourceClient`) to correctly parse the\n    API's specific list response structure.\n\n    To use this mixin, a class must:\n    1. Inherit from `BaseResourceClient` (or a class that provides the\n       `ResourceClientProtocol` attributes).\n    2. Define `_entity_path: str` specifying the API endpoint path for the resource.\n    3. Optionally, define `_search_response_model: type[BaseModel] | None`.\n       If provided, the entire search response (including pagination details and\n       results) will be parsed into an instance of this model. If None, the raw\n       JSON response dictionary is returned.\n    4. Optionally, define `_valid_sort_fields: frozenset[str]` if you want to\n       validate the `sort_by` parameter against a predefined set of fields.\n    \"\"\"\n\n    async def search(\n        self: ResourceClientProtocol,\n        page: int = 1,\n        page_size: int = 20,\n        sort_by: str | None = None,\n        filters: BaseModel | dict[str, Any] | None = None,\n    ) -&gt; BaseModel | dict[str, Any]:\n        \"\"\"Search for entities with pagination support.\n\n        Args:\n            page: Page number (1-indexed).\n            page_size: Number of results per page.\n            sort_by: Field to sort by (e.g., 'title asc', 'date desc').\n            filters: Filter criteria as a Pydantic model or dictionary.\n\n        Returns:\n            Any: Search results, either as a parsed Pydantic model (if\n                _search_response_model is defined) or as raw response data.\n\n        Raises:\n            BibliofabricError: If the API request fails.\n        \"\"\"\n\n        if not self._entity_path:\n            raise BibliofabricError(\n                f\"{self.__class__.__name__} must define _entity_path\"\n            )\n\n        # Convert filters to dictionary if it's a Pydantic model\n        filter_dict: dict[str, Any] = {}\n        if filters:\n            if isinstance(filters, BaseModel):\n                filter_dict = filters.model_dump(exclude_none=True, by_alias=True)\n            elif isinstance(filters, dict):\n                filter_dict = filters\n            else:\n                raise BibliofabricError(\n                    f\"filters must be a Pydantic model or dictionary, got {type(filters)}\"\n                )\n\n        filter_dict[\"page\"] = page\n        filter_dict[\"pageSize\"] = page_size\n\n        if sort_by:\n            filter_dict[\"sortBy\"] = sort_by\n\n        logger.info(\n            f\"Searching {self._entity_path}: page={filter_dict.get('page')}, size={filter_dict.get('pageSize')}, \"\n            f\"sort='{filter_dict.get('sortBy')}', filters={filter_dict}\"\n        )\n\n        # Build query parameters\n        params: dict[str, Any] = {\n            \"page\": page,\n            \"pageSize\": page_size,\n        }\n\n        if sort_by:\n            if (\n                hasattr(self, \"_valid_sort_fields\")\n                and sort_by.split()[0] not in self._valid_sort_fields  # type: ignore[attr-defined]\n            ):\n                raise ValidationError(f\"Invalid sort field: {sort_by.split()[0]}\")\n            params[\"sortBy\"] = sort_by\n\n        if filter_dict:\n            params.update(filter_dict)\n\n        try:\n            response = await self._api_client.request(\n                \"GET\", self._entity_path, params=params\n            )\n\n            response_data = response.json()\n\n            # Parse with search response model if available\n            if self._search_response_model:\n                try:\n                    return self._search_response_model.model_validate(response_data)\n                except Exception as e:\n                    logger.warning(\n                        f\"Failed to parse search response with {self._search_response_model.__name__}: {e}. \"\n                        \"Returning raw data.\"\n                    )\n                    return response_data\n\n            return response_data\n\n        except Exception as e:\n            if isinstance(e, BibliofabricError):\n                raise\n            logger.exception(\n                f\"Failed to search {self._entity_path} with params {params}\"\n            )\n            raise BibliofabricError(\n                f\"Unexpected error searching {self._entity_path}: {e}\"\n            ) from e\n</code></pre>"},{"location":"resources/#bibliofabric.resources.SearchableMixin.search","title":"<code>search(page=1, page_size=20, sort_by=None, filters=None)</code>  <code>async</code>","text":"<p>Search for entities with pagination support.</p> <p>Parameters:</p> Name Type Description Default <code>page</code> <code>int</code> <p>Page number (1-indexed).</p> <code>1</code> <code>page_size</code> <code>int</code> <p>Number of results per page.</p> <code>20</code> <code>sort_by</code> <code>str | None</code> <p>Field to sort by (e.g., 'title asc', 'date desc').</p> <code>None</code> <code>filters</code> <code>BaseModel | dict[str, Any] | None</code> <p>Filter criteria as a Pydantic model or dictionary.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>BaseModel | dict[str, Any]</code> <p>Search results, either as a parsed Pydantic model (if _search_response_model is defined) or as raw response data.</p> <p>Raises:</p> Type Description <code>BibliofabricError</code> <p>If the API request fails.</p> Source code in <code>src/bibliofabric/resources.py</code> <pre><code>async def search(\n    self: ResourceClientProtocol,\n    page: int = 1,\n    page_size: int = 20,\n    sort_by: str | None = None,\n    filters: BaseModel | dict[str, Any] | None = None,\n) -&gt; BaseModel | dict[str, Any]:\n    \"\"\"Search for entities with pagination support.\n\n    Args:\n        page: Page number (1-indexed).\n        page_size: Number of results per page.\n        sort_by: Field to sort by (e.g., 'title asc', 'date desc').\n        filters: Filter criteria as a Pydantic model or dictionary.\n\n    Returns:\n        Any: Search results, either as a parsed Pydantic model (if\n            _search_response_model is defined) or as raw response data.\n\n    Raises:\n        BibliofabricError: If the API request fails.\n    \"\"\"\n\n    if not self._entity_path:\n        raise BibliofabricError(\n            f\"{self.__class__.__name__} must define _entity_path\"\n        )\n\n    # Convert filters to dictionary if it's a Pydantic model\n    filter_dict: dict[str, Any] = {}\n    if filters:\n        if isinstance(filters, BaseModel):\n            filter_dict = filters.model_dump(exclude_none=True, by_alias=True)\n        elif isinstance(filters, dict):\n            filter_dict = filters\n        else:\n            raise BibliofabricError(\n                f\"filters must be a Pydantic model or dictionary, got {type(filters)}\"\n            )\n\n    filter_dict[\"page\"] = page\n    filter_dict[\"pageSize\"] = page_size\n\n    if sort_by:\n        filter_dict[\"sortBy\"] = sort_by\n\n    logger.info(\n        f\"Searching {self._entity_path}: page={filter_dict.get('page')}, size={filter_dict.get('pageSize')}, \"\n        f\"sort='{filter_dict.get('sortBy')}', filters={filter_dict}\"\n    )\n\n    # Build query parameters\n    params: dict[str, Any] = {\n        \"page\": page,\n        \"pageSize\": page_size,\n    }\n\n    if sort_by:\n        if (\n            hasattr(self, \"_valid_sort_fields\")\n            and sort_by.split()[0] not in self._valid_sort_fields  # type: ignore[attr-defined]\n        ):\n            raise ValidationError(f\"Invalid sort field: {sort_by.split()[0]}\")\n        params[\"sortBy\"] = sort_by\n\n    if filter_dict:\n        params.update(filter_dict)\n\n    try:\n        response = await self._api_client.request(\n            \"GET\", self._entity_path, params=params\n        )\n\n        response_data = response.json()\n\n        # Parse with search response model if available\n        if self._search_response_model:\n            try:\n                return self._search_response_model.model_validate(response_data)\n            except Exception as e:\n                logger.warning(\n                    f\"Failed to parse search response with {self._search_response_model.__name__}: {e}. \"\n                    \"Returning raw data.\"\n                )\n                return response_data\n\n        return response_data\n\n    except Exception as e:\n        if isinstance(e, BibliofabricError):\n            raise\n        logger.exception(\n            f\"Failed to search {self._entity_path} with params {params}\"\n        )\n        raise BibliofabricError(\n            f\"Unexpected error searching {self._entity_path}: {e}\"\n        ) from e\n</code></pre>"}]}